<p>Authoring of scholarly articles is a recurring theme in this blog since it started in 2008. Authoring is still in desperate need for improvement, and nobody has convincingly figured out how to solve this problem. Authoring involves several steps, and it helps to think about them separately:</p>
<ul>
<li><strong><strong>Writing</strong></strong>. Manuscript writing, including formatting, collaborative authoring</li>
<li><strong><strong>Submission</strong></strong>. Formatting a manuscript according to a publisher’s author guidelines, and handing it over to a publishing platform</li>
<li><strong><strong>Revision</strong></strong>. Changes made to a manuscript in the peer review process, or after publication</li>
</ul>
<p>Although authoring typically involves text, similar issues arise for other research outputs, e.g research data. And these considerations are also relevant for other forms of publishing, whether it is self-publication on a blog or website, or publishing of preprints and white papers.</p>
<figure>
<img src="http://blog.martinfenner.org/images/grammar.jpg" class="kg-image" alt="Flickr photo by citnaj." /><figcaption aria-hidden="true">Flickr photo by <a href="http://www.flickr.com/photos/citnaj/1278021067/">citnaj</a>.</figcaption>
</figure>
<p>For me the main challenge in authoring is to go from human-readable unstructured content to highly structured machine-readable content. We could make authoring simpler by either forgoing any structure and just publishing in any format we want, or we can force authors to structure their manuscripts according to a very specific set of rules. The former doesn’t seem to be an option, not only do we have a set of community standards that have evolved for a very long time (research articles for example have title, authors, results, references, etc.), but it also makes it hard to find and reuse scholarly research by others.</p>
<p>The latter option is also not really viable since most researchers haven’t learned to produce their research outputs in machine-readable highly standardized formats. There are some exceptions, e.g. <a href="http://www.consort-statement.org/">CONSORT</a> and other reporting standards in clinical medicine or the <a href="http://blogs.ch.cam.ac.uk/pmr/2012/01/23/brian-mcmahon-publishing-semantic-crystallography-every-science-data-publisher-should-watch-this-all-the-way-through/">semantic publishing in Crystallography</a>, but for the most part research outputs are too diverse to easily find a format that works for all of them. The current trend is certainly towards machine-readable rather than towards human-readable, but there is still a significant gap - scholarly articles are transformed from documents in Microsoft Word (or sometimes LaTeX) format into XML (for most biomedical research that means <a href="http://jats.nlm.nih.gov/publishing/">JATS</a>) using kludgy tools and lots of manual labor.</p>
<p>What solutions have been tried to overcome the limitations of our current authoring tools, and to make the process more enjoyable for authors and more productive for publishers?</p>
<ol>
<li>Do the conversion manually, still a common workflow.</li>
<li>Tools for publishers such as <a href="http://blogs.plos.org/mfenner/2009/05/01/extyles_interview_with_elizabeth_blake_and_bruce_rosenblum/">eXtyles</a>, <a href="http://www.shabash.net/merops/">Merops</a> - both commercial - or the evolving Open Source <a href="http://www.lib.umich.edu/mpach/modules">mPach</a> that convert Microsoft Word documents into JATS XML and do a lot of automated checks along the way.</li>
<li>Tools for authors that directly generate JATS XML, either as a Microsoft Word plugin (the <a href="http://blogs.nature.com/mfenner/2008/11/07/interview-with-pablo-fernicola">Article Authoring Add-In</a>, not actively maintained) in the browser (e.g. <a href="http://blogs.plos.org/mfenner/2009/02/27/lemon8_xml_interview_with_mj_suhonos/">Lemon8-XML</a>, not actively maintained), or directly in a publishing platform such as Wordpress (<a href="http://annotum.org/">Annotum</a>).</li>
<li>Forget about XML and use HTML5 has the canonical file format, e.g. as <a href="http://blogs.plos.org/mfenner/2011/03/19/a-very-brief-history-of-scholarly-html/">Scholarly HTML</a> or HTML5 specifications such as <a href="https://github.com/oreillymedia/HTMLBook/blob/master/specification.asciidoc">HTMLBook</a>. Please read Molly Sharp’s <a href="http://blogs.plos.org/tech/structured-documents-for-science-jats-xml-as-canonical-content-format/">blog post</a> for background information about HTML as an alternative to XML.</li>
<li>Use file formats for authoring that are a better fit for the requirements of scholarly authors, in particular <a href="http://blog.martinfenner.org/2012/12/13/a-call-for-scholarly-markdown/">Scholarly Markdown</a>.</li>
<li>Build online editors for scientific content that hide the underlying file format, and guide users towards a structured format, e.g. by not allowing input that doesn’t conform to specifications.</li>
</ol>
<p><strong><strong>Solution 1.</strong></strong> isn’t really an option, as it makes scholarly publishing unnecessarily slow and expensive. Typesetter Kaveh Bazergan has gone on record at the <a href="http://www.nature.com/spoton/2012/11/spoton-london-2012-a-global-conference/">SpotOn London Conference 2012</a> by saying that the current process is insane and that he wants to be “put out of business”.</p>
<p><strong><strong>Solution 2.</strong></strong> is probably the most commonly used workflow used by larger publishers today, but is very much centered around a Microsoft Word to XML workflow. LaTeX is a popular authoring environment in some disciplines, but still requires work to convert documents into web-friendly formats such as HTML and XML.</p>
<p><strong><strong>Solutions 3. to 5.</strong></strong> have never picked up any significant traction. Overall the progress in this area has been modest at best, and the mainstream of authoring today isn’t too different from 20 years ago. Although I have gone on record for saying that <a href="http://blog.martinfenner.org/tags.html#markdown-ref">Scholarly Markdown</a> has a lot of potential, the problem is much bigger than finding a single file format, and markdown will never be the solution for all authoring needs.</p>
<p><strong><strong>Solution 6.</strong></strong> is an area where a lot of exciting development is currently happening, examples include <a href="https://www.authorea.com/">Authorea</a>, <a href="https://www.writelatex.com/">WriteLateX</a>, <a href="https://www.sharelatex.com/">ShareLaTeX</a>. Although the future of scholarly authoring will certainly include online authoring tools (making it much easier to collaborate, one of the authoring pain points), we run the risk of locking in users into one particular authoring environment.</p>
<h3 id="going-forward">Going Forward</h3>
<p>How can we move forward? I would suggest the following:</p>
<ol>
<li>Publishers should accept manuscripts in any reasonable file format, which means at least Microsoft Word, Open Office, LaTeX, Markdown, HTML and PDF, but possibly more. This will create a lot of extra work for publishers, but will open the doors for innovation, both in the academic and commercial sector. We will never see significant progress in scholarly authoring tools if the submission step requires manuscripts to be in a single file format (Microsoft Word) - in particular since this file format is a general purpose word processsing format and not something designed specifically for scholarly content. And we want researchers to spend their time doing research and writing up their research, not formatting documents.</li>
<li>To handle this avalanche of unstructured documents, publishers need conversion tools that can transform all these documents into a format that can feed into their editorial and publishing workflows. A limited number of these tools exist already, but this will require a significant development effort. Again, opening up submissions to a variety of file formats will not only foster innovation in authoring tools, but also in document conversion tools.</li>
<li>We should think beyond XML. Many of the workflows designed today center around conversions from one XML format to another, e.g. Microsoft Word to JATS or <a href="http://www.tei-c.org/index.xml">TEI</a> (popular in the humanities), often using XLST transforms. Not only is XML difficult for humans to read or edit, but the web and many of the technologies built around it are moving away from XML towards HTML5 and JSON. XML is fine as an important output format for publishing, but maybe not the best format to hold everything together.</li>
<li>As we haven’t come up with a canoical file format for scholarly documents by now, we should give up that idea. XML is great for publisher workflows, but is not something humans can easily edit or read. PDF is still the most widely read format by humans, but is not a good intermediary format. LaTeX is too complex for authors outside of mathematics, physics and related fields, and is not built with web standards in mind. Markdown is promising, but doesn’t easily support highly structured content. And HTML5 and the related ePub are widely popular, but can be hard to edit without a visual editor, and currently don’t include enough standard metadata to support scholarly content out of the box.</li>
<li>The focus should not be on canonical file formats for scholarly documents, but on tools that understand the manuscripts created by researchers and can transform them into something more structured. As we have learned from document conversion tools such as <a href="http://johnmacfarlane.net/pandoc/">Pandoc</a>, we can’t do this with a simple find and replace using regular expressions, but need a more structured approach. Pandoc is taking the input document (markdown, LaTeX or HTML) apart and is constructing an abstract syntax tree (<a href="http://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a>) of the document, using parsing expression grammar (<a href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">PEG</a>), which includes a set of parsing rules. Parsing expression grammars are fairly new, <a href="http://bford.info/pub/lang/peg">first described by Bryan Ford</a> about 10 years ago, but in my mind are a very good fit for the formal grammar of scientific documents. It should be fairly straightforward to generate a variety of output formats from the AST (Pandoc can convert into more than 30 document formats), the hard part is the parsing of the input.</li>
</ol>
<p>All this requires a lot of work. Pandoc is a good model to start, but is written in Haskell, a functional programming language that not many people are familar with. For small changes Pandoc allows you to directly manipulate the AST (represented as JSON) using <a href="http://johnmacfarlane.net/pandoc/scripting.html">filters</a> written in Haskell or Python. And <a href="https://github.com/jgm/pandoc">custom writers</a> for other document formats can be written using <a href="http://www.lua.org/">Lua</a>, another interesting programming language that not many people know about. Lua is a fast and relatively easy to learn scripting language that can be easily embedded into other languages, and for similar reasons is also used to <a href="http://en.wikipedia.org/wiki/Wikipedia:Lua">extend the functionality of Wikipedia</a>. PEG parsers in other languages include <a href="http://treetop.rubyforge.org/">Treetop</a> (Ruby), <a href="http://pegjs.majda.cz/">PEG.js</a> (Javascript), and <a href="http://www.antlr.org/">ANTLR</a>, a popular parser generator that also includes PEG features.</p>
<p>But I think the effort to build a solid open source conversion tool for scholarly documents is worth it, in particular for smaller publishers and publishing platforms who can’t afford the commercial Microsoft Word to JATS conversion tools. We shouldn’t take any shortcuts - e.g. by focussing on XML and XLST transforms - and we can improve this tool over time, e.g. by starting with a few input and output formats. This tool will be valuable beyond authoring, as it can also be very helpful to convert published scholarly content into other formats such as ePub, and in text mining, which in many ways tries to solve many of the same problems. The <a href="http://johnmacfarlane.net/pandoc/scripting.html">Pandoc documentation</a> includes an example of extracting all URLs out of a document, and this can be modified to extract other content. In case you wonder whether I gave up on the idea of <a href="http://blog.martinfenner.org/tags.html#markdown-ref">Scholarly Markdown</a> - not at all. To me this is a logical next step, opening up journal submission systems to Scholarly Markdown and other evolving file formats. And Pandoc, one of the most interesting tools in this space, is a markdown conversion tool at its heart. The next steps could be the following:</p>
<ul>
<li>write a custom writer in Lua that generates JATS output from Pandoc</li>
<li>explore how difficult it would be to add Microsoft Word .docx as Pandoc input format</li>
<li>develop Pandoc filters relevant for scholarly documents (e.g. <a href="http://blog.martinfenner.org/2013/07/02/auto-generating-links-to-data-and-resources/">auto-linking accession numbers of biomedical databases</a>)</li>
</ul>
<hr />
