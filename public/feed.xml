<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://sensiblescience.io/</id>
    <title>Sensible Science</title>
    <updated>2021-03-14T20:33:05.895Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <author>
        <name>Martin Fenner</name>
        <email>mf@martinfenner.org</email>
    </author>
    <link rel="alternate" href="https://sensiblescience.io/"/>
    <link rel="self" href="https://sensiblescience.io/feed.xml"/>
    <subtitle>Martin Fenner writes about how the internet is changing scholarly communication.</subtitle>
    <rights>Copyright © 2007-2021 Martin Fenner. Distributed under the terms of the Creative Commons Attribution 4.0 License.</rights>
    <entry>
        <title type="html"><![CDATA[Thank you PLOS]]></title>
        <id>ae704746-6ec6-4d90-b126-d88206036d2f</id>
        <link href="https://sensiblescience.io/mfenner/thank-you-plos"/>
        <updated>2015-07-29T10:52:00.000Z</updated>
        <summary type="html"><![CDATA[Starting next week I will work as the DataCite Technical Director, and I am excited about this new opportunity. But this is material for another post, here I want to reflect on the last three years working as Technical Lead for the PLOS Article-Level...]]></summary>
        <content type="html"><![CDATA[<p><a href="https://www.datacite.org/news/martin-fenner-and-laura-rueda-join-datacite-team.html">Starting next week</a> I will work as the DataCite Technical Director, and I am excited about this new opportunity. But this is material for another post, here I want to reflect on the last three years working as Technical Lead for the <a href="http://lagotto.io/plos/">PLOS Article-Level Metrics</a> project.</p>
<p>It feels much longer than three years, but until May 2012 I worked as medical oncologist at Hannover Medical School, treating patient with cancer, attending interdisciplinary tumor boards and helping with clinical trials. It was a very brave move by PLOS to hire me at this point, especially since I <a href="https://sensiblescience.io/mfenner/why-should-we-work-where-we-live">worked remotely</a> from Germany rather than in the San Francisco office. I will be forever thankful to PLOS for giving me this opportunity.</p>
<p>Two factors probably played a role in this decision: I have been blogging about how the internet is changing scholarly communication since 2007, and since September 2010 I had <a href="http://blogs.plos.org">my blog on the PLOS Blogs Network</a>. I had also visited the PLOS offices in San Francisco, and had met several PLOS people at conferences, including Pete Binfield, Rich Cave, Mark Patterson, Brian Mossop, Jennifer Lin and Liz Allen. I had <a href="https://sensiblescience.io/mfenner/plos-one-interview-with-peter-binfield">interviewed</a> Pete Binfield about PLOS ONE and the PLOS Article-Level Metrics project in August 2009, shortly after the project was launched.</p>
<p>The other factor was the hackathon at the 2011 Science Online London conference. We were a really small group of people (I remember Jason Hoyt, Victor Henning, Kristi Holmes and Cameron Neylon, Mendeley was hosting the event), but I had the idea to hack the open source PLOS Article-Level Metrics application. This hack turned into <a href="https://sensiblescience.io/mfenner/announcing-sciencecard/">ScienceCard</a>, a version of the PLOS Article-Level Metrics application focussing on people rather than articles, and the application was a finalist for the <a href="http://blog.mendeley.com/highlighting-research/the-top-101-apps-in-the-mendeley-plos-binary-battle/">Mendeley/PLOS API Binary Battle</a>. ScienceCard doesn’t exist anymore, but the concept of organizing metrics around a person lives on in ImpactStory, facilitated by the launch of ORCID in October 2012. More importantly - without me knowing it - ScienceCard demonstrated that I could work with and extend the PLOS Article-Level Metrics code, and I think I was the first person outside of PLOS doing this. Which must have helped when PLOS was looking for a technical lead for the project a few months later.</p>
<p>In other words, blogging and hacking code can lead to great job opportunities.</p>
<p>While at PLOS I not only learned a ton of things about article-level metrics and all its challenges and opportunities, but also many basic skills needed in software development. Which is important, as my formal training is in clinical medicine and molecular biology, and doing software development in your free time (which I had done since the 1990s) only gets you so far. Some of the unexpected things I learned:</p>
<ul>
<li><strong><strong>Visualizations</strong></strong>: while it was clear that I was expected to generate visualizations for the PLOS Article-Level Metrics data, I didn’t expect this to go so deep, first with R and later with <a href="http://d3js.org/">d3.js</a>. Najko Jahn introduced me to using R to analyze the PLOS data, and I later worked closely with Scott Chamberlain from the <a href="https://ropensci.org/">rOpenSci</a> project to help improve their <a href="https://ropensci.org/tutorials/alm_tutorial.html">alm package</a>. The Javascript work with d3.js started with AlmViz at the 2012 ALM hackathon and later was done in close collaboration with Juan Alperin from the <a href="https://pkp.sfu.ca/">Public Knowledge Project</a>.</li>
<li><strong><strong>DevOps</strong></strong>: the intersection of software development and system administration. I became a big fan and have spent endless hours learning how to automate the configuration and deployment of servers and other infrastructure.</li>
<li><strong>O<strong>pen source community building</strong></strong>: again something I was expected to do around the PLOS article-level metrics open source application, but I never expected this to be so challenging and time-consuming, but also rewarding.</li>
</ul>
<p>I thank everyone at PLOS who I had the pleasure to work with over the years, in particular Kristen Ratan, Cameron Neylon, Donna Okubo, Mei Yan Leung, Liz Allen, Catriona MacCallum, Matt Hodgkinson, Theo Bloom, Damian Pattinson, Ginny Barbour, Emma Ganley, Roli Roberts, Eric Martens, Susan Au, Matt Willman, Edgar Munoz, Rachel Drysdale, CJ Rayhill, Lisa Siegel, Jennifer Song, Polina Grinbaum, John Bertrand, Mike Baehr, Clark Hartsock, Adam Hyde, and Holly Allen. A very special thanks goes to Jennifer Lin, Rich Cave and John Chodacki who worked with me on a daily basis.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Component DOIs Revisited]]></title>
        <id>0983610b-64df-4dff-96dc-5de43c56a237</id>
        <link href="https://sensiblescience.io/mfenner/component-dois-revisited"/>
        <updated>2015-07-09T10:19:00.000Z</updated>
        <summary type="html"><![CDATA[Four years ago I wrote a blog post about component DOIs. It is time to revisit the topic, in particular since our approach to citing data associated with a publication has changed since 2011.Component DOIs are explained in the CrossRef Help System:DOIs...]]></summary>
        <content type="html"><![CDATA[<p>Four years ago I wrote a <a href="https://sensiblescience.io/mfenner/direct-links-to-figures-and-tables-using-component-dois/">blog post</a> about component DOIs. It is time to revisit the topic, in particular since our approach to citing data associated with a publication has changed since 2011.</p>
<p>Component DOIs are explained in the <a href="http://help.crossref.org/components">CrossRef Help System</a>:</p>
<blockquote>
DOIs may be assigned to items that are part of a journal article, book chapter, or any other content item. A component would typically be a figure, table, or image which is part of or referred to by the parent item. Assigning a DOI to a component allows direct linking to the component item.
</blockquote>
<p>Component DOIs are DOIs, i.e. persistent identifiers that link directly to the resource in question, e.g. a figure in a publication. The component DOI for a figure in a PLOS paper used in the 2011 post still <a href="https://doi.org/10.1371/journal.pone.0006022.g002">works as expected</a>, despite changes to the URL of the journal landing page.</p>
<p>The problem with component DOIs is the problem with DOIs in general: there is basic functionality common to all DOIs, and there are additional services specific to subgroups of DOIs. This confuses users - in particular since there is no easy way to immediately see what kind of DOI they have in front of them - and in the case of component DOIs there is one important feature missing.</p>
<p>DOis are assigned by registration agencies (CrossRef and DataCite are the most relevant ones for scholarly content), and these RAs have built different services around DOIs, e.g. different ways to describe and search the metadata (title, authors, etc.) associated with a DOI. Component DOIs are again different, the most important difference is that in the CrossRef implementation they they are not discoverable by <a href="https://doi.org/10.3789/isqv22n3.2010.06">querying the CrossRef system</a>. Component DOIs are also always associated with a parent DOI (for the article, book, etc.). Although this is the expected behavior, we shouldn’t expect component DOIs to always look like an extension of the parent DOI, as in <code>10.1371/journal.pone.0006022.g002</code> used in the example above.</p>
<p>In essence, a component DOI is a <strong><strong>DOI light</strong></strong>. We can use them for persistent linking, but we can’t use them for discovery via the CrossRef Metadata Search (and by extension other indexing services). A common use case for component DOIs is supplementary information in a journal article. Content in supplementary information files is already much harder to find than content in the body of an article, using component DOIs instead of regular DOIs makes the content again harder to find.</p>
<p>All of this might not have been much of an issue when I wrote the 2011 post, but making the data underlying a publication publicly available and discoverable is increasingly becoming something that funders, publishers and institutions expect. Most of these data are not deposited in dedicated data repositories, but in supplementary information files (for PLOS articles published since March 2014 this is true for more than 50% of papers). Using regular DOIs for supplementary information files with proper metadata and proper inclusion in indexing services will make it easier to find, access and reuse these data.</p>
<p>Unfortunately that still leaves us with the problem that the supplementary information files then will have CrossRef DOIs, whereas data repositories typically use DataCite DOIs, so that we need to search for these datasets in two different places. But that is material for another post.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why should we work where we live?]]></title>
        <id>66d00cb0-23c6-4e9d-9561-7dab13ffaa63</id>
        <link href="https://sensiblescience.io/mfenner/why-should-we-work-where-we-live"/>
        <updated>2015-06-28T10:23:00.000Z</updated>
        <summary type="html"><![CDATA[At the SciFoo Camp this weekend Erin McKiernan and I moderated an unconference session on the topic <strong>Why should we work where we live?</strong> This was a spontaneous idea after we had talked about this topic on Friday (Erin lives in Mexico with a job in Canada,...]]></summary>
        <content type="html"><![CDATA[<p>At the <a href="http://www.digital-science.com/events/scifoo-camp-2015/">SciFoo Camp</a> this weekend <a href="https://emckiernan.wordpress.com/">Erin McKiernan</a> and I moderated an unconference session on the topic <strong>Why should we work where we live?</strong> This was a spontaneous idea after we had talked about this topic on Friday (Erin lives in Mexico with a job in Canada, I live in Germany and work for an organization in San Francisco).</p>
<p>We quickly realized that this situation is far from uncommon in the space we work in (science and science communication). Most commonly the reason is compromises we have to make when both partners have to find an adequate job. It can be a big challenge for a couple to find senior jobs in academia in the same city or region, especially outside of academic clusters such as Boston, New York or London.</p>
<p>The other big reason for work remote is that some research can only happen in special places, for example in high-energy physics, astronomy or the geosciences. And of course there are other flavors of the same situation, e.g. when a principal investigator moves to a new institution and PhD students or postdocs can’t or don’t want to move with him/her. And most academics have to do at least some remote work, since they will spend a good amount of time travelling to conferences or collaboration partners.</p>
<p>The discussion in the session centered on the social and technical challenges of working remotely. We didn’t have time to go into the legal aspects (e.g. taxes when you work in a different country), or the challenges organizing your personal life, particular difficult when you have children.</p>
<p>We shared our experience with online collaboration tools, and video conferencing with Skype, Google Hangouts or similar was central to this. Videoconferencing can be a challenge with slow internet connectivity, a situation that luckily is constantly improving.</p>
<p>Private group chat tool such as <a href="https://en.wikipedia.org/wiki/HipChat">HipChat</a> or <a href="https://slack.com/">Slack</a> are becoming increasingly popular outside the Tech sector and are a great alternative to email. They not only provide a platform for quick messages between two people, but also serve as a backchannel for informal “water cooler” discussions in an organization.</p>
<p>Another essential category is tools that track your work so that your remote colleagues not only can collaborate with you, but also see the work you are doing. As a supervisor you quickly see the work that was done the past week, a much more reasonable approach than looking at physical presence at work (where people might be doing all kinds of other things and personal productivity varies). Tracking your work is easy if you are a software developer like me and can look at code committed to version control, tickets closed, etc. For research this is more challenging, in particular if the workflow is not digital yet and for example all experiments are documented in a paper notebook. It seems that one requirement for remote work in science is digitalization of your work, but that is a direction we are heading anyway and which has other advantages (e.g. improving reproducibility). If there are no specialized tools for documenting your work available, then a note-taking tool such as <a href="https://www.onenote.com/">OneNote</a> or <a href="https://evernote.com/">Evernote</a> can be helpful. The digitization and automation of work is obviously limited in wet labs that require direct interactions with samples and instruments.</p>
<p>The social aspects of remote work might be the bigger challenge. There is still a big reluctance in supervisors and administrators to this, assuming that people will only be productive if someone is watching them. This assumption is very short sighted, as what drives PhDs and postdocs to work hard is not supervision, but the intrinsic motivation to accomplish something, in particular in light of the very competitive situation for permanent jobs in academia. The book <a href="http://37signals.com/remote/">Remote</a> by Jason Fried talks about this in great detail in the context of software development, but the same principles apply to work in science. What supervisors and administrators loose in direct oversight they can in attracting talent they would otherwise not get. Remote work only works if supported by the host institution, for example by adapting internal workflows and communications to make remote work the default rather than an exception.</p>
<p>Remote work is usually more successful and satisfying if combined with physical presence at the workplace. Reasons for this are not only the part of the work that can’t be done remotely, but more importantly the social aspect. How extensive this physical presence is depends on the circumstances. Some level of remote work has become part of almost everyone’s job in science, as it includes working at home in the evenings or on weekends, or work while traveling.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Persistent Identifiers and URLs]]></title>
        <id>f89e2997-a9e4-4924-bd70-16231baec3e6</id>
        <link href="https://sensiblescience.io/mfenner/persistent-identifiers-and-urls"/>
        <updated>2015-06-03T10:43:00.000Z</updated>
        <summary type="html"><![CDATA[Just like the rest of the internet, much of our scholarly infrastructure is built around the Hypertext Transfer Protocol (HTTP), increasingly HTTPS for security, and soon HTTP/2 for better performance. In this infrastructure Universal Resource Locators (URLs)...]]></summary>
        <content type="html"><![CDATA[<p>Just like the rest of the internet, much of our scholarly infrastructure is built around the Hypertext Transfer Protocol (HTTP), increasingly HTTPS for security, and soon <a href="https://http2.github.io/">HTTP/2</a> for better performance. In this infrastructure Universal Resource Locators (URLs) are essential to locate resources (sic) such as scholarly articles, datasets, researchers, organizations, or grants. Read <a href="http://site.thomsonreuters.com/site/data-identifiers/">this</a> recent Thomson Reuters report for a good recent perspective on this topic. While this works for the most part, there are some issues with URLs - not specific to scholarly content, but particularly import here:</p>
<ol>
<li>multiple URLs can point to the same resource</li>
<li>URLs can be long and look ugly</li>
<li>URLs can change or break, making it hard or impossible to locate the resource</li>
<li>we are used to central indexes (or databases) describing these resources, allowing us to do sophisticated queries not possible in a generic web search, e.g. find all publications by author John Doe, published since 2012.</li>
</ol>
<p>No. 1 is a problem relevant to all URLs, e.g. web searches or liking/commenting a particular web page. Originally suggested by Google, <a href="https://support.google.com/webmasters/answer/139066?hl=en">Canonical URLs</a> are essential for services such as Facebook or <a href="https://hypothes.is/blog/cross-format-annotation/">Hypothes.is</a>. They have been formalized in <a href="http://tools.ietf.org/html/rfc6596">rfc6596</a> and are commonly used.</p>
<p>No. 2 can be a problem, in particular if we are not careful in designing appropriate URLs for landing pages (see next paragraph), but rather use something long and unreadable that also includes query parameters, etc. If we have no control over how the URL looks like, we can use URL shortener services such as <a href="https://bitly.com/">bit.ly</a>, which of course have become a common sight on the web. <a href="http://shortdoi.org/">ShortDOIs</a> are an URL shortener for DOIs, but they don’t seem to have gained much traction.</p>
<p>No. 3 is a particularly important issue, commonly referred to as <strong><strong>link rot</strong></strong> and described extensively for the scholarly literature, e.g. by <a href="https://doi.org/10.1371/journal.pone.0115253">Klein</a>. There are several technical solutions to this problem, a common approach is to use a landing page for the resource that will never change (and follows the recommendations by Tim Berners-Lee for <a href="http://www.w3.org/Provider/Style/URI.html">Cool URIs</a>, and then use redirection to point to the current location of the resource. This is easily for changes of the URL path using web server <a href="http://httpd.apache.org/docs/2.4/rewrite/remapping.html">redirect rules</a>. It gets more complicated if the server name also changes, in particular if it is the server holding the landing page. Thinking this through you realize that the only way this can be done on a larger scale is via one or more centralized services that not only provide the technical infrastructure for a central redirection (or resolver) service, but also come with a social contract of rules that everyone submitting URLs to the service has to follow - a major difference to URL shorteners, which don’t solve the link rot problem.</p>
<p>The above is of course a description of the DOI service provided by CrossRef, DataCite, and others, as well as similar persistent identifier services. Unfortunately some persistent identifier services don’t do the above: they create and use persistent identifiers, but there is no central resolver service that maps these identifiers back to URLs. This breaks the integration with the bigger scholarly infrastructure based on URLs. One common example are nucleotide sequences such as U65091, there is no single corresponding URL because the sequence can be found in all three main nucleotide databases: <a href="http://www.ncbi.nlm.nih.gov/nuccore/U65091">http://www.ncbi.nlm.nih.gov/nuccore/U65091</a>. It would help to have a central resolver, e.g. http://nucleotide.org/U65091 that then redirects to one of the three databases based on geographical location or user preference.</p>
<p>There are also problems with DOIs. They use the <a href="http://www.handle.net/">Handle</a> system to resolve the identifier to a location, and this system was built in the 1990s as infrastructure <a href="http://www.handle.net/faq.html">independent of</a> URLs or DNS (Domain Name Service), at a time when it wasn’t clear yet that URLs and associated standards would become ubiquitous. I don’t have numbers, but practically all DOIs are of course now resolved to URLs using the <a href="http://www.doi.org/factsheets/DOIProxy.html">DOI proxy server</a> at http://doi.org (preferred) or http://dx.doi.org. One main consequence of this is that DOIs are frequently not written as URLs - e.g. doi:10.5555/24242424x instead of <a href="https://doi.org/10.5555/24242424x">https://doi.org/10.5555/24242424x</a> - again breaking the integration with the bigger scholarly infrastructure. The CrossRef <a href="http://www.crossref.org/02publishers/doi_display_guidelines.html">DOI display guidelines</a> clearly state that DOIs should be written as URLs in <em>the online environment</em>, which basically is whenever DOIs are used, as PDFs and even Word documents know how to handle URLs. Unfortunately this guideline is still frequently ignored. The above is of course also true for other persistent identifiers using the Handle system, e.g. <a href="http://www.pidconsortium.eu/">ePIC</a>.</p>
<p>The other problem with the DOI system is that it doesn’t address issue No. 4, i.e. provide a central metadata index for the resources that use the system. This job is left to the DOI registration agencies such as CrossRef and DataCite, who have implemented a central metadata store (e.g. <a href="https://search.crossref.org/">CrossRef</a> or <a href="https://search.datacite.org/">DataCite</a>) in different ways (e.g. using different metadata schemata), or not at all. This means that we have to look in several places to find all DOIs associated with author John Doe, published since 2012. Obviously we are used to looking up information in multiple places, but not being able to look up the metadata for a DOI without some extra work (finding out the registration agency for the DOI and then going to the respective metadata store) is a problem. One way around these problems is to use the <a href="https://citation.crosscite.org/docs.html">DOI Content Negotiation Service</a>.</p>
<p>Another problem with the DOI system is more a social than a technical issue. Neither CrossRef nor DataCite seem to enforce that DOIs should always resolve to URLs when using a computer program. DOI resolution for humans works fine, but computers, e.g. command line tools such as cURL, can run into issues such as requiring cookies, javascript or user input, or permission problems getting to the journal landing page (see <a href="https://sensiblescience.io/mfenner/challenges-in-automated-doi-resolution">this earlier blog post</a> for some numbers). People seem to forget that a DOI that is not actionable is not really useful, and that scholarly infrastructure is not only used by people, but of course also by automated tools.</p>
<p>The persistent identifiers used in our scholarly infrastructure would benefit from a clearer focus on the problems they should solve, starting with No. 1-4 above. One problem is that we probably focus too much on the persistence problem, implied also by the term <strong><strong>persistent identifier</strong></strong> or <strong><strong>PID</strong></strong>. What we have neglected is the resolvable problem, i.e. making as easy as possible to get from the persistent identifier to the resource and/or its metadata. Based on the Den Haag Manifesto and suggested by Todd Vision, we therefore proposed the term <strong><strong>trusted identifier</strong></strong> with the following characteristics in the <a href="https://doi.org/10.6084/m9.figshare.824314">conceptual model of interoperability</a> for the <a href="http://odin-project.eu/">ODIN Project</a>:</p>
<ul>
<li>are unique on a global scale, allowing large numbers of unique identifiers</li>
<li>resolve as HTTP URI’s with support for content negotiation, and these HTTP URI’s should be persistent.</li>
<li>come with metadata that describe their most relevant properties, including a minimum set of common metadata elements. A search of metadata elements across all trusted identifiers of that service should be possible.</li>
<li>are interoperable with other identifiers through metadata elements that describe their relationship.</li>
<li>are issued and managed by an organization that focuses on that goal as its primary mission, has a sustainable business model and a critical mass of member organizations that have agreed to common procedures and policies, has a governing body, and is committed to using open technologies.</li>
</ul>
<p>While not directly relevant for resolving persistent identifiers as URLs, the last point is really important for any persistent identifier infrastructure, <a href="https://doi.org/10.6084/m9.figshare.1314859">described in detail recently</a>.</p>
<p>If I would design a persistent identifier service today (as if we would need yet another persistent identifier service), I would build the system around an URL shortening service that I control. The URLs could look very similar to what we have with DOIs now, e.g. <a href="http://doi.org/10.5555/12345678">https://doi.org/10.5555/12345678</a>, but it would be clear that persistent identifiers are URLs, not something separate. Plus we could take advantage of all the lessons learned - and possibly even reuse open source code - with URL shorteners, which are much more widely used than scholarly persistent identifiers.</p>
<p><em>Update 6/4/15: added link to Thomson Reuters <a href="http://site.thomsonreuters.com/site/data-identifiers/">report</a> on identifiers and open data.</em></p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Human-readable and machine-readable Persistent Identifiers]]></title>
        <id>e92e15e3-4449-4e6e-b901-f36aabc6fb36</id>
        <link href="https://sensiblescience.io/mfenner/human-readable-and-machine-readable-persistent-identifiers"/>
        <updated>2015-05-27T10:45:00.000Z</updated>
        <summary type="html"><![CDATA[Yesterday Julie McMurry and co-authors published a preprint <strong><strong>10 Simple rules for design, provision, and reuse of persistent identifiers for life science data</strong></strong>. This is an important paper trying to address a fundamental...]]></summary>
        <content type="html"><![CDATA[<p>Yesterday Julie McMurry and co-authors <a href="https://doi.org/10.5281/zenodo.18003">published a preprint</a> <strong><strong>10 Simple rules for design, provision, and reuse of persistent identifiers for life science data</strong></strong>. This is an important paper trying to address a fundamental problem: how can we make persistent identifiers both human-readable and machine-readable?</p>
<p>Don’t be fooled by the title (used frequently by <a href="https://collections.plos.org/collection/ten-simple-rules/">PLOS Computational Biology</a>) - the paper doesn’t describe simple rules that help the average life sciences researcher. Rather, the paper deals with rather complex issues, and has 36 authors.</p>
<p>There is general agreement that we need persistent identifiers for scholarly communication, and that also includes life sciences datasets, the focus of the paper. What is less clear is how to express these persistent identifiers. An identifier such as <strong><strong>AB020317</strong></strong> - for the mouse p53 gene - is ambiguous. It is not clear without additional information that this is an identifier for the GenBank nucleotide database, rather than <a href="https://www.flickr.com/photos/alexcycu/8936663973/">something completely different</a>. One common approach to make this identifier unambiguous is to use URIs (Uniform Resource Identifiers), e.g. <a href="http://www.ncbi.nlm.nih.gov/nuccore/AB020317">http://www.ncbi.nlm.nih.gov/nuccore/AB020317</a> in this case.</p>
<p>The paper doesn’t like this approach, and even states that “URIs are still among the most commonly used and most problematic identifiers in the bio-data ecosystem”. The text also states that “their length makes them unwieldy for humans working with the data or for referencing in publications or other text”, but doesn’t go into any detail why URIs are “problematic identifiers”, or why length is an issue in an online environment.</p>
<p>This is an important weakness of the paper, because the authors propose an alternative: CURIEs or <strong><strong>compact URIs</strong></strong>. CURIEs were <a href="http://www.w3.org/TR/curie/">proposed</a> by the W3C a few years ago, as a way to make URIs <a href="https://www.crossref.org/blog/curies-a-cure-for-uris/">more human-readable</a>. The idea is simple, we use a namespace in addition to the local identifier, separated by a colon, e.g. <strong><strong><a href="http://www.ebi.ac.uk/ena/data/view/AB020317">Genbank:AB020317</a></strong></strong>.</p>
<p>This approach has of course been common practice in the life sciences before CURIEs or even the WWW existed, and is still the most common approach how identifiers for life sciences data are referenced in the scholarly literature. Unfortunately there are important problems with CURIEs, most of them mentioned in the paper:</p>
<ul>
<li>Persistent identifiers need to be resolvable, without additional information we don’t know what to do with <strong><strong><a href="http://www.ebi.ac.uk/ena/data/view/AB020317">Genbank:AB020317</a></strong></strong>. Most life sciences researchers understand this CURIE, but that might not necessarily be true for less commonly used namespaces</li>
<li>Namespaces are not necessarily unique, the paper uses <strong><strong>GEO</strong></strong> (which could mean Gene Expression Omnibus or GeoNames Ontology) as an example</li>
<li>Rule 3 in the paper goes into great detail what characters and patterns should be avoided in local identifiers that are part of a CURIE. It is not clear whether these recommendations will always be followed or how to check them</li>
<li>CURIEs should follow a pattern (regular expression) so that they can be extracted from a text. We <a href="https://doi.org/10.1371/journal.pone.0063184">know</a> that extracting identifiers from journal articles is possible, but difficult.</li>
</ul>
<p>URIs don’t have the problems listed above: they resolve, are unique, and there is good understanding (and available tools) of how a valid URI should look like and how to extract URIs from text documents. That is why URIs are good representations of persistent identifiers.</p>
<p>Another problem I have with CURIEs: the idea doesn’t seem to have caught on from the initial work more than five years ago (background reading <a href="http://manu.sporny.org/2011/case-for-curies/">here</a>). I’m not even sure what percentage of persistent identifier experts know about CURIEs.</p>
<p>My recommendation for life sciences data: express persistent identifiers as URIs. Now that can go into 10 simple rules for the average life sciences researcher.</p>
<p><em>P.S. This blog uses a tool <a href="http://sensiblescience.io/mfenner/auto-generating-links-to-data-and-resources/">I wrote two years ago</a> that automatically turns CURIEs in the text into links.</em></p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing the Scholarly Markdown Bundle]]></title>
        <id>c53ee3a5-a102-4482-be12-09f53966469a</id>
        <link href="https://sensiblescience.io/mfenner/introducing-the-scholarly-markdown-bundle"/>
        <updated>2015-04-23T11:48:00.000Z</updated>
        <summary type="html"><![CDATA[Using Markdown to author scholarly documents is an attractive alternative to the standard authoring tools Microsoft Word and LaTeX. The feeling shared by many is that Scholarly Markdown is 80% there, and that more effort is needed for the remaining 20%...]]></summary>
        <content type="html"><![CDATA[<p>Using Markdown to author scholarly documents is an attractive alternative to the standard authoring tools Microsoft Word and LaTeX. The feeling shared by many is that <a href="https://sensiblescience.io/mfenner/what-is-scholarly-markdown/">Scholarly Markdown</a> is 80% there, and that more effort is needed for the remaining 20% - moving markdown from a niche into the mainstream. What is mainly needed is building tools that connect the existing tools and ideas, resulting in one or more services attractive to a critical number of users. But maybe we also need to rethink the essential parts of Scholarly Markdown. In this post I propose that we expand the concept and define the <em>Scholarly Markdown Bundle</em>.</p>
<p>It is becoming increasingly clear that scholarly work can’t be adequately described in a single text document, most commonly the journal article. Not only are there associated metadata, assets such as figures and supplementary information, but also the research data and software needed to produce the work described in the publication. The obvious next step is to think of scholarly work as a collection of objects, most clearly described by Carol Goble and others as <a href="https://researchobject.github.io/specifications/bundle/">Research Object Bundle</a>.</p>
<p>There will probably never be a single authoring tool and format that pleases everyone. Markdown has particular inherent strengths and weaknesses, complex math or tables will probably always be easier with other formats. The strength of markdown is the simplicity of the format. Some things are hard or impossible to do, but many other things are much simpler. Creating a useful markdown editor is much easier than a word processor reading/writing <code>docx</code> format. Markdown is also a perfect format to <a href="https://sensiblescience.io/mfenner/using-microsoft-word-with-git/">work with</a> version control systems such as git.</p>
<p>This low barrier of entry makes markdown perfect to be integrated into many workflows. And we can go one step further than ePub and Research Object Bundle, which use the related Universal Container Format (<a href="https://wikidocs.adobe.com/wiki/display/PDFNAV/Universal+Container+Format">UCF</a>) and ePub Open Container Format (<a href="http://www.idpf.org/epub/301/spec/epub-ocf.html">OCF</a>), respectively. Instead of using zip to compress a folder into a single file we can use git version control instead: git provides the commands <code>git bundle</code> and <code>git archive</code> to compress a project under version control with or without version history. I feel this format is both more powerful So I propose the <em>Scholarly Markdown Bundle</em>:</p>
<ul>
<li>a git repository with one or more markdown files, either as a folder, or compressed into a single file using <code>git bundle</code></li>
<li>a particular flavor or markdown called Scholarly Markdown, and discussed here and elsewhere before</li>
<li>a <code>citeproc.json</code> file in the root of the project that contains all metadata relevant to the container, including references</li>
</ul>
<p>The <code>citeproc.json</code> file is similar to the minimal metadata schema <a href="https://github.com/mbjones/codemeta">codemeta</a> proposed by Matt Jones and others, but is in the format used by Pandoc today. This is <a href="https://sensiblescience.io/mfenner/citeproc-yaml-for-bibliographies/">important</a> because it adds citation parsing support out of the box. The last two points rely on the <a href="http://pandoc.org/">Pandoc</a> document conversion tool, so Scholarly Markdown bundles are really <strong><strong>markdown</strong></strong> + <strong><strong>Pandoc</strong></strong> + <strong><strong>Citeproc/CSL</strong></strong> + <strong><strong>git</strong></strong>. The format is flexible enough to not only describe scholarly articles, but also other kinds of scholarly works, including scientific software managed with git version control. And it integrates nicely with a number of existing workflows, e.g. an R project using RStudio for both code and text (in Rmarkdown). This format should also work for blogs like this one, but I would have to separate the blog posts from the Jekyll site generator code, a direction I suggested in the <a href="https://sensiblescience.io/mfenner/blogging-beyond-jekyll/">last</a> post.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blogging Beyond Jekyll]]></title>
        <id>4bdd1c2c-0b6f-4035-88a2-5c51e9a32055</id>
        <link href="https://sensiblescience.io/mfenner/blogging-beyond-jekyll"/>
        <updated>2015-03-23T11:50:00.000Z</updated>
        <summary type="html"><![CDATA[This blog has been on four different platforms since starting in 2007: a custom blogging engine and then Movable Type on Nature Network 2007-2010, Wordpress on the PLOS Blogs Network 2010-2013, and the static blogging engine Jekyll hosted on Github Pages since 2013....]]></summary>
        <content type="html"><![CDATA[<p>This blog has been on four different platforms since starting in 2007: a custom blogging engine and then <a href="https://movabletype.org/">Movable Type</a> on <a href="http://network.nature.com/">Nature Network</a> 2007-2010, Wordpress on the <a href="http://blogs.plos.org">PLOS Blogs Network</a> 2010-2013, and the static blogging engine <a href="https://jekyllrb.com/">Jekyll</a> hosted on Github Pages since 2013. It might be time for yet another blogging platform change.</p>
<p>The main reason to switch from Wordpress to Jekyll was the concept of a static site generator: write posts in <a href="http://commonmark.org/">markdown format</a>, store them in a Github repository, and then have Jekyll automatically generate the HTML pages hosted on <a href="https://pages.github.com/">Github Pages</a>. The main attraction was the blog posts in markdown format stored in git version control without the need of a database. Jekyll is the glue to make all this work, and I was able to customize Jekyll to my needs, e.g. by using <a href="https://pandoc.org/">Pandoc</a> for the markdown to html conversion.</p>
<p>While this workflow still makes sense for this blog, there are a number of shortcomings:</p>
<ul>
<li>Jekyll needs to rebuild the entire site every time I publish a new post. While this isn’t much of a problem for the size of this blog, it doesn’t scale well for larger sites. And the process is more complex if you use custom jekyll plugins like this blog, as you can’t use the automatic Jekyll pipeline provided by Github (hint: use a Travis continuous integration server <a href="https://sensiblescience.io/mfenner/continuous-publishing/">to build the site</a>)</li>
<li>the web is moving to increasingly sophisticated javascript frontends, using frameworks such as <a href="https://angularjs.org/">Angular.js</a>, <a href="http://emberjs.com/">Ember.js</a>, or frontend libraries for scholarly documents such as <a href="http://elifesciences.org/elife-news/lens">Lens</a>. While they can be used together with Jekyll, that is not a typical use case.</li>
<li>the tight integration between the code to generate the website and the content (Wordpress and other blogging engines have the same approach) is not always the best solution, e.g. when you want to want to generate the pages for something that is not a blog (e.g. a <a href="http://book.openingscience.org/">book</a>).</li>
</ul>
<p>What could we do instead?</p>
<blockquote>
Build a Javascript frontend where the content is served via an API built around markdown documents, stored in git version control.
</blockquote>
<h3 id="api">API</h3>
<p>The blog posts are still written in markdown, stored (and version-controlled in a Github repository), but we would now access the content via API. The easiest solution is to use the <a href="https://developer.github.com/v3/repos/contents/">Github Contents API</a> and either do the markdown to html conversion in javascript yourself, or let the Github API do the conversion to HTML for you. Alternatively we could build our own API, e.g. because we want to control the markdown to html conversion, or need additional functionality such as fulltext search. And of course the two approaches can be combined, e.g. via a Github webhook that triggers the markdown to html conversion every time a document is added or updated, and stores the converted documents in the same repo.</p>
<h3 id="frontend">Frontend</h3>
<p>The frontend should be written as a one-page javascript application, not requiring a server backend. In contrast to the Jekyll workflow the frontend code doesn’t need to be updated every time we post a blog post. Since this is a very common scenario, there are probably several solutions out there already. Please mention them in the comments if you have suggestions. One candidate is <a href="https://github.com/elifesciences/lens/">Lens</a> mentioned above - a beautiful frontend for scholarly documents. Lens displays documents in the <a href="http://jats.nlm.nih.gov/publishing/tag-library/1.0/index.html">JATS</a> XML format, so your API would have to provide that format.</p>
<h3 id="conclusions">Conclusions</h3>
<p>The separation into API and frontend is of course old news. But for blogs this seems to still be a fairly new concept, in particular when combined with a backend using documents stored in git version control rather than in a database. Wordpress added a <a href="https://wordpress.org/plugins/json-rest-api/">REST API Plugin</a> in 2014, and the Ghost blogging framework (which uses a database backend) also seems to <a href="https://trello.com/b/EceUgtCL/ghost-roadmap">go into that general direction</a>. Please ping me if you like the idea and want to contribute, or have implemented something like this already.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metadata in Microsoft Word documents]]></title>
        <id>5398a86a-fd4c-439d-9773-34527b79ac7d</id>
        <link href="https://sensiblescience.io/mfenner/metadata-in-microsoft-word-documents"/>
        <updated>2015-03-20T11:52:00.000Z</updated>
        <summary type="html"><![CDATA[Metadata such as author, title, journal or persistent identifier are essential for scholarly documents, and some of us are spending a significant part of our time adding or fixing metadata. Unfortunately we sometimes don’t pay enough attention to the flow of metadata,...]]></summary>
        <content type="html"><![CDATA[<p>Metadata such as author, title, journal or persistent identifier are essential for scholarly documents, and some of us are spending a significant part of our time adding or fixing metadata. Unfortunately we sometimes don’t pay enough attention to the flow of metadata, i.e. we ignore already existing metadata, or reinvent the wheel in how we describe or store them.</p>
<p>Storing metadata in text-based formats is usually straightforward. This blog post is written in markdown with a <a href="http://yaml.org/">YAML header</a> - think of YAML as the more human-readable version of JSON - at the beginning of the document:</p>
<pre><code>---
title: Metadata in Microsoft Word documents
---</code></pre>
<p>This is then translated into this HTML when the blog post is published:</p>
<pre><code>&lt;meta property=&quot;dc:title&quot; content=&quot;Metadata in Microsoft Word documents&quot; /&gt;</code></pre>
<p>XML is of course a very natural format for metadata, here for example <a href="http://jats.nlm.nih.gov/publishing/tag-library/1.0/index.html">JATS</a> used for scholarly articles:</p>
<pre><code>&lt;article-title&gt;Metadata in Microsoft Word documents&lt;/article-title&gt;</code></pre>
<p>Many scholarly documents start out as Microsoft Word documents. And while the <code>docx</code> format introduced by Microsoft in Microsoft Office 2007 <a href="http://officeopenxml.com/">is XML-based</a>, few users are aware of this fact. And probably even fewer users (including myself) ever go to the <code>Properties…</code> settings of a <code>docx</code> document and add a <code>title</code>, <code>keywords</code> or other metadata (the <code>author</code> is usually set automatically).</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/IC164149.gif" class="kg-image" alt="Microsoft Word 2007 Properties. Image from Microsoft Developer Network" /><figcaption aria-hidden="true">Microsoft Word 2007 Properties. Image from <a href="https://msdn.microsoft.com/en-us/library/bb308936(v=office.12).aspx">Microsoft Developer Network</a></figcaption>
</figure>
<p>This is very unfortunate, as these metadata are very often required, e.g. in a journal article submission, and then need to be collected again, usually either by asking the author to fill out a web form, and/or by extracting the metadata (e.g. title) from the document.</p>
<p>The best place for metadata is with the document (not <em>in</em> the document), and if the file format (<code>docx</code> in this case) supports it, we should take advantage of this. The main benefit: metadata stay with the text when the document is sent to co-authors via email, or put on a file server, or into Dropbox.</p>
<p>In the case of <code>docx</code>, the metadata support is actually pretty good, using the standard <a href="http://dublincore.org/">Dublin Core</a>, and storing the metadata in a separate file called <code>core.xml</code>. You can see this file if you unzip your <code>docx</code> file (e.g. after giving it a <code>zip</code> extension). The <code>core.xml</code> file for this blog post (after converting the markdown file to <code>docx</code> using <a href="https://pandoc.org">Pandoc</a>) looks like this:</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;cp:coreProperties xmlns:cp=&quot;http://schemas.openxmlformats.org/package/2006/metadata/core-properties&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:dcterms=&quot;http://purl.org/dc/terms/&quot; xmlns:dcmitype=&quot;http://purl.org/dc/dcmitype/&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;&lt;dc:title&gt;Metadata in Microsoft Word documents&lt;/dc:title&gt;&lt;dc:creator&gt;&lt;/dc:creator&gt;&lt;/cp:coreProperties&gt;</code></pre>
<p>Because <code>docx</code> is XML, we can read/write this file not only in Microsoft Word, e.g. using macros, but also outside of Microsoft Word, e.g. in workflows that converts <code>docx</code> documents into other formats, or tools that check <code>docx</code> files for required metadata (e.g. by using <a href="https://sensiblescience.io/mfenner/introducing-rakali/">rakali</a> that I wrote last year). So please encourage authors to use the Microsoft Word <code>Properties…</code> settings, and update existing tools to take advantage of the Dublin Core metadata stored in every <code>docx</code> file.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[First analysis of software metrics]]></title>
        <id>f66851ce-9224-4c1b-b880-4fa675d01b05</id>
        <link href="https://sensiblescience.io/mfenner/first-analysis-of-software-metrics"/>
        <updated>2015-02-28T11:55:00.000Z</updated>
        <summary type="html"><![CDATA[Last week I wrote about software.lagotto.io, an instance of the lagotto open source software collecting metrics for the about 1,400 software repositories included in Sciencetoolbox. In this post I want to report the first results analyzing the data.If you want to follow along,...]]></summary>
        <content type="html"><![CDATA[<p>Last week <a href="https://sensiblescience.io/mfenner/metrics-for-scientific-software/">I wrote about</a> software.lagotto.io, an instance of the <a href="https://github.com/articlemetrics/lagotto">lagotto</a> open source software collecting metrics for the about 1,400 software repositories included in Sciencetoolbox. In this post I want to report the first results analyzing the data.</p>
<p>If you want to follow along, please go to <a href="https://github.com/mfenner/software-analysis">https://github.com/mfenner/software-analysis</a>, this repository holds all the data, as well as the R code used for analysis. A special thanks goes to <a href="http://scottchamberlain.info/">Scott Chamberlain</a> who greatly helped me by tweaking the <a href="https://github.com/ropensci/alm">alm</a> R package to support URLs instead of DOIs as identifiers.</p>
<p>The first step in the analysis is to get an overview of the external sources citing or discussing the software package:</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/software.lagotto.io_2.png" class="kg-image" alt="Number of software repositories (out of 1,404) with at least one event. Data from software.lagotto.io" /><figcaption aria-hidden="true">Number of software repositories (out of 1,404) with at least one event. Data from <a href="http://software.lagotto.io">software.lagotto.io</a></figcaption>
</figure>
<p>This is basically the same figure as in the <a href="https://sensiblescience.io/mfenner/metrics-for-scientific-software/">previous post</a>, but with two differences: I have added a <a href="http://www.nature.com/opensearch/">Nature.com OpenSearch</a> data source, and I have found an additional 64 repositories cited in scholarly articles via an Europe PMC full-text Search that also includes the reference lists (thanks to <a href="http://www.ebi.ac.uk/about/people/johanna-mcentyre">Jo McEntyre</a>).</p>
<p>I am not sure why we are not picking up any Wikipedia citations, and have to take a closer look. The ORCID source also needs tweaking, and there are some issues with the <a href="http://wordpress.com/">Wordpress.com</a> data that I have to look into as well. Citations in the scholarly literature are obviously the most interesting data, and we have three Github repos with more than 25 citations, including <a href="https://github.com/najoshi/sickle">https://github.com/najoshi/sickle</a> with 54 citations. As most repositories in our sample are cited only once if at all, a correlation with Github stars and forks is not useful. Sickle is popular on Github (52 stars and 32 forks), but it is not clear that this activity is correlated to citations (e.g. because there are more citations than stars).</p>
<p>The vast majority of software repos in this analysis are hosted by Github, so we have the numbers of stars and forks for those. It is interesting, although probably not very surprising, that the number of Github stargazers and forks is highly correlated:</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/github_likes_readers-1.png" class="kg-image" alt="Correlation between Github stargazers and forks, log-log scale. Data from software.lagotto.io" /><figcaption aria-hidden="true">Correlation between Github stargazers and forks, log-log scale. Data from <a href="http://software.lagotto.io">software.lagotto.io</a></figcaption>
</figure>
<p>We can find Facebook activity (likes, comments or shares) for one third of the repositories. There is a reasonably good correlation between Facebook activity and number of Github forks:</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/facebook_github_readers-1.png" class="kg-image" alt="Correlation between combined Facebook activity and Github forks, log-log scale. Data from software.lagotto.io" /><figcaption aria-hidden="true">Correlation between combined Facebook activity and Github forks, log-log scale. Data from <a href="http://software.lagotto.io">software.lagotto.io</a></figcaption>
</figure>
<p>One interesting analysis would be to look at the repositories that have been forked much more often relative to their Facebook activity, e.g. <a href="https://github.com/cloudera/impala">Impala</a> with 1,207 Github stars and 458 forks, but only 5 Facebook shares. One limitation of the analysis is that we are not tracking Facebook (or other social media) activity for all forks of a repo.</p>
<p>We found Reddit discussions mentioning one of the repositories in 7% of cases. Once we have a larger sample size it would be interesting to correlate this activity with Github stars and forks, similar to what we did for Facebook. By far the most popular repository from our sample on Reddit is <a href="https://github.com/Bitcoin/Bitcoin">Bitcoin</a>, followed by <a href="https://github.com/jquery/jquery">JQuery</a>. Twitter activity is notoriously difficult to collect since Twitter doesn’t keep tweets very long, hence probably the low numbers compared to Facebook and Reddit.</p>
<p>Feel free to play with the data and scripts provided at <a href="https://github.com/mfenner/software-analysis">https://github.com/mfenner/software-analysis</a>, my next step is probably to include a much larger number of software repositories.</p>
<p>It has not escaped our notice that the kind of analysis described above could be applied to any software repository, not just scientific software.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why there is no iTunes for science papers]]></title>
        <id>b898d6d8-3030-455c-b08a-108215ba2b97</id>
        <link href="https://sensiblescience.io/mfenner/why-there-is-no-itunes-for-science-papers"/>
        <updated>2015-02-23T11:58:00.000Z</updated>
        <summary type="html"><![CDATA[The iTunes Store was opened by Apple in 2003 to sell digital music and other digital assets. Since 2009 music purchased in the iTunes store is free of Digital Rights Management (DRM). Apple became the largest music vendor worldwide in 2010,...]]></summary>
        <content type="html"><![CDATA[<p>The iTunes Store was opened by Apple in 2003 to sell digital music and other digital assets. Since 2009 music purchased in the iTunes store is free of Digital Rights Management (DRM). Apple became the largest music vendor worldwide in 2010, and by 2013 had sold 25 billion songs.</p>
<p>Scholarly articles are distributed almost exclusively in digital form. While there is an increasing number of journal articles freely available via green or gold open access, the majority of them still can only be read if the reader works at an institution with a subscription to the journal. Many journals also allow the reader to buy a single article of interest, for prices between $10 and more than $30:</p>
<figure>
<img src="https://editor.sensiblescience.io/content/images/2021/01/pay_per_view_nature-1.png" class="kg-image" sizes="(min-width: 720px) 720px" srcset="https://editor.sensiblescience.io/content/images/size/w600/2021/01/pay_per_view_nature-1.png 600w, https://editor.sensiblescience.io/content/images/size/w1000/2021/01/pay_per_view_nature-1.png 1000w, https://editor.sensiblescience.io/content/images/2021/01/pay_per_view_nature-1.png 1150w" alt="For an article in Nature" /><figcaption aria-hidden="true">For an article in Nature</figcaption>
</figure>
<figure>
<img src="https://editor.sensiblescience.io/content/images/2021/01/pay_per_view_lancet-1.png" class="kg-image" srcset="https://editor.sensiblescience.io/content/images/size/w600/2021/01/pay_per_view_lancet-1.png 600w, https://editor.sensiblescience.io/content/images/2021/01/pay_per_view_lancet-1.png 606w" alt="For an article in Lancet" /><figcaption aria-hidden="true">For an article in Lancet</figcaption>
</figure>
<p>There is also a document delivery service provided by libraries, but that option varies considerably by country and in Germany for example means a scanned article as printout rather than the original PDF because of a change in German copyright law a few years ago. There are also the services <a href="https://www.deepdyve.com/">DeepDyve</a> and <a href="https://www.readcube.com/">ReadCube</a>, but again you don’t get the PDF (or only for prices similar to those quoted above), but rather limited access for reading and printing.</p>
<p>In summary, affordable access to scholarly content by subscription publishers is in a dire state: you either have to work at an academic institution subscribing to the desired journal, get only a crippled version of the article (online viewing only), or pay up to $30 for a single article, which clearly doesn’t scale beyond very occasional use.</p>
<p>With this background it is obvious that several people have discussed the iTunes Store-like model to sell scholarly articles:</p>
<ul>
<li><a href="http://crosstech.crossref.org/2009/09/prc_report_and_ipub_revisited.html">PRC Report and “iPub” revisited</a></li>
<li><a href="http://www.popsci.com/science/article/2009-10/deepdyve-launches-itunes-science-papers">DeepDyve launches iTunes Store-like service for science papers</a></li>
<li><a href="http://scienceblogs.com/digitalbio/2012/01/10/could-an-itunes-like-model-wor/">Could an iTunes-like model work with scientific publishing?</a></li>
<li><a href="http://www.bostonglobe.com/business/2012/10/07/start-readcube-program-uses-itunes-payment-model-for-access-scientific-articles/1UopCX1qfEE3uO2UEzuM7L/story.html">A plan to open up science journals</a></li>
<li><a href="http://www.newyorker.com/tech/elements/when-the-rebel-alliance-sells-out">When the Rebel Alliance Sells Out</a></li>
</ul>
<p>The best already existing platforms to build such as service are reference managers, as most of them have learned now to manage PDF files, and have an online component. ReadCube is offering a pay-per-view option already, Papers, Mendeley, Endnote or others could get into this business.</p>
<p>One of the big advantages of payments for single articles is transparency, as institutions and users only pay for what they actually use. Price transparency is one of the big problems with the <em>big deal</em> contracts that academic institutions have with publishers - read <a href="https://doi.org/10.1073/pnas.1403006111">this article</a> for more info.</p>
<p>But rather than becoming the predominant way to pay for digital music, services such as DeepDyve and ReadCube are only playing a marginal role. Why is that so?</p>
<ul>
<li>whereas digital music is paid for by the consumer, there is usually a middleman in the form of the library for scholarly articles, which makes the payment process more complex.</li>
<li>subscription publishers have focused all their efforts on selling big deals with increasing numbers of journals to libraries. Prices of $30 per article are clearly intended to discourage payment for single articles (which could jeopardize journal bundles) rather than offering an earnest payment option.</li>
<li>Apple was in a strong negotiation position with record labels when starting the iTunes store (the extremely popular iPod, record labels scared of file-sharing platforms such as Napster). No organization is in a similar position with scientific publishers, and services such as ReadCube or Mendeley are handicapped because they are associated with a particular publisher</li>
</ul>
<p>Unless several large publishers and/or a smart third-party with enough muscle start an initiative in this space, e.g. by bringing the pay-per-view prices to a reasonable level (e.g. $4.99), we will never see an iTunes Store-like service for scholarly articles, and this currently looks like the most likely outcome. We may have reached the point where it is too late, as most publishers seem to already work towards another payment model: gold open access where the authors pay the article costs.</p>
<p><em>Update 3/2/15: added link to 2009 CrossTech blog post.</em></p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Metrics for scientific software]]></title>
        <id>31c00475-7abf-4bc8-830c-4b37bafa0359</id>
        <link href="https://sensiblescience.io/mfenner/metrics-for-scientific-software"/>
        <updated>2015-02-19T12:00:00.000Z</updated>
        <summary type="html"><![CDATA[One of the challenges of collecting metrics for scholarly outputs is persistent identifiers. For journal articles the Digital Object Identifier (DOI) has become the de-facto standard, other popular identifiers are the pmid from PubMed,...]]></summary>
        <content type="html"><![CDATA[<p>One of the challenges of collecting metrics for scholarly outputs is persistent identifiers. For journal articles the Digital Object Identifier (DOI) has become the de-facto standard, other popular identifiers are the pmid from PubMed, the identifiers used by Scopus and Web of Science, and the arxiv ID for ArXiV preprints.</p>
<p>For other research outputs the picture is less clear. DOIs are also used for datasets, but so are many other identifiers, in particular in the life sciences.</p>
<p>To collect metrics for research outputs, the requirements are slightly different. We need identifiers understood by the services collecting the metrics, not by the data repository or other service that is holding the research output (the only exception is usage stats, which are generated locally). For many services, in particular social media such as Facebook, Twitter or Reddit, the primary identifier for a resource is a URL. This means that we should have one or more URLs for every research output where we want to track the metrics - typically the publisher or data repository landing page. Since URLs can be messy, Google, Facebook and others have come up with the concept of a <a href="http://googlewebmastercentral.blogspot.de/2009/02/specify-your-canonical.html">canonical URL</a>, and some care should go into constructing proper canonical URLs (see <a href="https://sensiblescience.io/mfenner/challenges-in-automated-doi-resolution">this blog post</a> for examples of what can go wrong).</p>
<p>The Den Haag Manifesto is the result of a <strong><strong>Knowledge Exchange</strong></strong> workshop held in June 2011 and tries to bring Persistent Identifiers and Linked Open Data together. The first principle is very much in line with what I said above:</p>
<blockquote>
Make sure PIDs can be referred to as HTTP URI’s, including support for content negotiation.
</blockquote>
<p>Or, to put this differently: URLs are good enough to start collecting metrics for scholarly outputs. Scientific software is a good example where persistent identifiers are not commonly used (despite efforts such as <a href="https://guides.github.com/activities/citable-code/">this one</a>), but we can still collect many meaningful metrics using the repository URL (and the open source software <a href="https://github.com/articlemetrics/lagotto">lagotto</a>):</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/14th/software.lagotto.io.png" class="kg-image" alt="Number of software repositories (out of 1,404) with at least one event. Data from software.lagotto.io" /><figcaption aria-hidden="true">Number of software repositories (out of 1,404) with at least one event. Data from software.lagotto.io</figcaption>
</figure>
<p>The last three rows are citations in the scholarly literature found via fulltext search of BioMed Central, Europe PMC and PLOS. URLs (in contrast to persistent identifiers represented as strings and/or numbers) are easy to find, the main limitation is not so much using a URL rather than a DOI, but that scientific software typically is mentioned in the text without appearing in the reference list. This makes it hard to impossible to find articles mentioning the software that are not open access, which unfortunately is still the majority of them.</p>
<p>We are of course also tracking the discussion of the software in social media, and are collecting the number of stars and forks in Github and Bitbucket. Overall there is quite a lot of activity, here are some examples:</p>
<ul>
<li><a href="https://github.com/najoshi/sickle">Windowed Adaptive Trimming for fastq files using quality</a></li>
<li><a href="https://github.com/lh3/wgsim">Reads simulator</a></li>
<li><a href="http://software.lagotto.io/works/url/https://github.com/lh3/seqtk">Toolkit for processing sequences in FASTA/Q formats</a></li>
</ul>
<p>All three software repos have been cited in the scholarly literature at least ten times. What is missing is infrastructure that tracks the citations of scientific software, so that we can give proper scientific credit to the authors of the software, and can discover other research projects using the same tools. software.lagotto.io uses a list of software repos collected by Jure Triglav for ScienceToolbox, and a scientific software index is indeed one of the important missing pieces.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Manifests and Reference Lists]]></title>
        <id>c19c5ec6-6e50-47fc-b51a-c5c2a97a9860</id>
        <link href="https://sensiblescience.io/mfenner/manifests-and-reference-lists"/>
        <updated>2015-02-05T12:03:00.000Z</updated>
        <summary type="html"><![CDATA[Last month at the Force15 conference in Oxford Ian Mulvany and I ran a workshop on data citation support in reference managers. The report of that workshop isn’t done yet, but I can say that it was a success - we now have a pretty good idea what the...]]></summary>
        <content type="html"><![CDATA[<p>Last month at the <a href="https://www.force11.org/meetings/force2015/pre-conference-meeting-list">Force15 conference</a> in Oxford <a href="https://twitter.com/IanMulvany">Ian Mulvany</a> and I ran a workshop on <a href="https://sensiblescience.io/mfenner/data-citation-support-in-reference-managers/">data citation support in reference managers</a>. The report of that workshop isn’t done yet, but I can say that it was a success - we now have a pretty good idea what the problems are and what needs to be done to fix them. The short summary of the workshop is in <a href="https://speakerdeck.com/mfenner/workshop-summary-reference-managers-and-data-citation">this</a> slide deck of the presentation that summarized the workshop for the other Force15 attendees.</p>
<p>The whole idea of the workshop was to treat data citation as similar as possible to the citation of journal articles, i.e. to allow authors to use the same tools (reference managers) and conventions (citation styles). Putting a data citation into a reference list makes it easier to find that data citation because reference lists contain more metadata, are more structured, and more accessible than data citations in the form of identifiers or links within the body text of the article.</p>
<p>But I have to admit that there is one problem with reference lists: although there is always some self-citation, reference lists usually contain references to articles (and other resources) created by other people and before the article was published. It feels a little bit odd to put a dataset created by the same group of people and published at the same time into the reference list. And although we could use a separate reference list or highlight the data associated with the article in some other way, what we really want is something slightly different, a manifest file.</p>
<p>The journal article has been a (mainly) textual document for many centuries not because this is the essence of science communication, but rather because there was no practical way to include all the other information (raw data, tools used for experiments, etc.). Very few of these limitations remain with the digital journal article that we have since the 1990s, but we have for the most part failed to change the format other than going from paper to PDF. One of many examples: figures in publications typically still are has limited as they were decades ago with no way to see the data underlying the figure, options for selecting what data points are shown, or animation for time-based information.</p>
<p>So what we really care about is the sum of artifacts and resources that together make what Carol Goble and others call <a href="https://doi.org/10.1038/npre.2010.4626.1">research object</a>, the journal article is an important part, but clearly doesn’t include everything that is needed to understand and reproduce the work. Reference lists can help with linking to some of the resources not included in the article text, but they typically don’t link to supplementary information or other places where the underlying data are made available, or to the figures of the article. Although some publishers provide navigation tools for readers to get to this information, what we really need is a machine-readable list of all the resources used in an article.</p>
<p>As it happens, this is exactly what the ePub format for electronic books is doing, as every ePub must include a manifest file that lists all the files that are part of the publication, defined in the <a href="http://www.idpf.org/epub/20/spec/OPF_2.0.1_draft.htm">Open Packaging Format (OPF)</a>. I need to do more research to figure out how to do this with <a href="http://jats.nlm.nih.gov/archiving/tag-library/1.0/index.html">JATS</a>, the standard for scholarly articles, and how to generate something similar to the manifest file when using different formats, e.g. html or markdown. This has to be linked to some of the information we are collecting already, e.g. described in <a href="https://doi.org/10.3998/3336451.0014.106">JATS</a>, or the <code>relatedIdentifier</code> in the <a href="https://doi.org/10.5438/0010">DataCite metadata</a>.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Citation Support in Reference Managers]]></title>
        <id>b36a3870-6498-4514-9102-2ee4763ef739</id>
        <link href="https://sensiblescience.io/mfenner/data-citation-support-in-reference-managers"/>
        <updated>2015-01-05T14:55:00.000Z</updated>
        <summary type="html"><![CDATA[This is the title of an upcoming workshop next Sunday organized by Ian Mulvany and myself. The workshop is a pre-conference event of the Force15 conference in Oxford. This blog post summarizes some of the issues and work that needs to be done.Data...]]></summary>
        <content type="html"><![CDATA[<p>This is the title of an upcoming workshop next Sunday organized by Ian Mulvany and myself. The workshop is a <a href="https://www.force11.org/meetings/force2015/pre-conference-meeting-list">pre-conference event</a> of the <a href="https://www.force11.org/meetings/force2015">Force15</a> conference in Oxford. This blog post summarizes some of the issues and work that needs to be done.</p>
<p>Data Citation is one of the big themes of the Force15 conference, and a lot of progress has been made, including the Joint Declaration of Data Citation Principles (Data Citation Synthesis Group 2014) that start with the following paragraph on <strong><strong>Importance</strong></strong>:</p>
<blockquote>
Data should be considered legitimate, citable products of research. Data citations should be accorded the same importance in the scholarly record as citations of other research objects, such as publications.
</blockquote>
<p>Convincing researchers, funders, university administrators and others that data citation is important is crucial. But for researchers to actually adopt data citation to the same degree as citations of the scholarly literature, more needs to be done:</p>
<ul>
<li>incentives (both carrots and sticks) by funders, institutions, and scholarly societies</li>
<li>training in data management</li>
<li>data repositories and other tools and services for the public sharing of data</li>
<li>tools and services that help citing those datasets</li>
</ul>
<p>The focus of the workshop is on the last bullet point, and I would argue that more work still needs to be done here compared to the first three bullet points.</p>
<h2 id="reference-managers">Reference Managers</h2>
<p>Researchers use reference managers to handle the citations in the manuscripts they write. This is both a common practice that everybody understands, and there are a plethora of tools - both free and paid - available. Most reference managers were originally built to handle citations of journal articles and maybe books or book chapters, and many of them also help with managing the associated PDF files. In the last 15 years we have seen an dramatic increase of non-article citations in reference lists, mainly to web resources (Klein et al., 2014):</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/journal.pone.0115253.g002.png" class="kg-image" alt="From Fig. 2: STM articles and URI references per publication year - Elsevier corpus (Klein et al. 2014)" /><figcaption aria-hidden="true">From Fig. 2: STM articles and URI references per publication year - Elsevier corpus (Klein et al. 2014)</figcaption>
</figure>
<p>References managers have started to adapt to these changes in citation patterns. Similarly they have become better in handling non-textual resources such as slide decks, datasets, or movies. Nobody should type in references by hand in 2015, as reference managers have come up with several ways of importing metadata about citations:</p>
<ul>
<li>import references stored in a file using a format such as BibTex or RIS</li>
<li>import references by talking to an external API</li>
<li>import references via a bookmarklet that grabs information from the current webpage in the browser</li>
</ul>
<p>Endnote and Papers typically use the second approach whereas Mendeley, Zotero (and others) work almost exclusively via bookmarklets (and there are of course combinations of both). Bookmarklets in general work better for web resources and other content that is not indexed in a central service such as Web of Science or Scopus. This is also true for research data, as there are currently few central research data indexing services - the Thomson Reuters <a href="http://wokinfo.com/products_tools/multidisciplinary/dci/">Data Citation Index</a> and <a href="https://www.datacite.org/">DataCite</a> are two examples in this category. But there are also thousands of data repositories, many of them listed in re3data (Pampel et al., 2013).</p>
<p>The reference manager <a href="https://www.zotero.org/">Zotero</a> has built a large open source ecosystem around bookmarklets (what they call <a href="https://github.com/zotero/translators">web translators</a>), making it straightforward to add support for a new resource, as I have done for <a href="https://github.com/zotero/translators/blob/master/NCBI%20Nucleotide.js">GenBank nucleotide sequence datasets</a> in November after learning the basics in a <a href="http://sensiblescience.io/mfenner/webinar-on-writing-zotero-translators/">webinar</a> given by Sebastian Karcher, a frequent contributor to Zotero web translators.</p>
<p>There is no technical reason that reference managers can’t support a broad range of objects to cite, including datasets. And integration of data citation into the reference manager workflow is not only the easiest and most natural way for the author of a paper, but also makes it easier to discover these citations - reference lists are simply much better for that than links in the text, in particular if the content is behind subscription walls. There is a long tradition in the life sciences to put identifiers for genetic sequences used in a publication right into the text (usually into the methods section). Links in the body text are worse than references in reference lists, <a href="http://sensiblescience.io/mfenner/auto-generating-links-to-data-and-resources/">identifiers without a link</a> are even worse, as they are very hard to find in an automated way (Kafkas, Kim, &amp; McEntyre, 2013).</p>
<p>Please come to our workshop on Sunday afternoon if you are in Oxford and are interested in this topic. <a href="https://www.eventbrite.com/e/data-citation-support-in-reference-managers-tickets-15136593960">Registration</a> is free, and the workshop will include both presentations about the current state of data citation support in the reference managers Endnote, Papers, Mendeley and Zotero, and work in smaller groups on practical implementations.</p>
<h2 id="references">References</h2>
<p>Kafkas, Ş., Kim, J.-H., &amp; McEntyre, J. R. (2013). Database Citation in Full Text Biomedical Articles. <em>PLoS ONE</em>. https://doi.org/<a href="https://doi.org/10.1371/journal.pone.0063184">10.1371/journal.pone.0063184</a></p>
<p>Klein, M., Van de Sompel, H., Sanderson, R., Shankar, H., Balakireva, L., Zhou, K., &amp; Tobin, R. (2014). Scholarly context not found: one in five articles suffers from reference rot. <em>PLoS ONE</em>, <em>9</em>(12), e115253. https://doi.org/<a href="https://doi.org/10.1371/journal.pone.0115253">10.1371/journal.pone.0115253</a></p>
<p>Pampel, H., Vierkant, P., Scholze, F., Bertelmann, R., Kindling, M., Klump, J., … Dierolf, U. (2013). Making Research Data Repositories Visible: The re3data.org Registry. <em>PLoS ONE</em>, <em>8</em>(11), e78080. https://doi.org/<a href="https://doi.org/10.1371/journal.pone.0078080">10.1371/journal.pone.0078080</a></p>
<p>Data Citation Synthesis Group. (2014). <em>Joint Declaration of Data Citation Principles</em>. Force11. <a href="https://doi.org/10.25490/A97F-EGYK">https://doi.org/10.25490/A97F-EGYK</a></p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Webinar on Writing Zotero Translators]]></title>
        <id>a7068104-63a6-4807-b229-9bf24eac6693</id>
        <link href="https://sensiblescience.io/mfenner/webinar-on-writing-zotero-translators"/>
        <updated>2014-10-17T14:59:00.000Z</updated>
        <summary type="html"><![CDATA[In a blog post two weeks ago I argued for the need for reference managers to properly support data citation, if we want data citation to become a standard activity. I am happy to announce two events working towards that goal.November 3rd: Webinar on writing Zotero web translatorsSebastian Karcher,...]]></summary>
        <content type="html"><![CDATA[<p>In a <a href="http://sensiblescience.io/mfenner/please-keep-it-simple-citations-links-and-references/">blog post two weeks ago</a> I argued for the need for reference managers to properly support data citation, if we want data citation to become a standard activity. I am happy to announce two events working towards that goal.</p>
<h2 id="november-3rd-webinar-on-writing-zotero-web-translators">November 3rd: Webinar on writing Zotero web translators</h2>
<p><a href="https://www.zotero.org/blog/community-spotlight-sebastian-karcher/">Sebastian Karcher</a>, one of the most prolific authors of Zotero web translators (and citation styles), has kindly offered to hold an introductory webinar on writing Zotero web translators. These web translators allow Zotero to import metadata about a scholarly work from a variety of places, and new web translators for repositories that hold research data (or software) would go a long way towards making data citation easier for authors. <a href="https://www.zotero.org/support/dev/translators">Web translators</a> are written in Javascript and only basic Javascript knowledge is required. The free webinar takes place on November 3rd on 5 PM UK time (12 PM EST) and the registration form is <a href="http://www.eventbrite.com/e/writing-zotero-translators-webinar-tickets-13768797845">here</a>.</p>
<h2 id="january-11-force11-pre-conference-workshop-on-data-citation-support-in-reference-managers">January 11: Force11 Pre-Conference workshop on Data Citation Support in Reference Managers</h2>
<p><a href="https://www.force11.org/meetings/force2015/pre-conference-meeting-list">This workshop</a>, co-organized with Ian Mulvany, will extend the Zotero web translator work to other reference managers, including Papers and Mendeley. This will be a hackathon with the goal to get some things working in these reference managers, but it should also be interesting for others, as we will discuss what is missing to make data citation work in reference managers.</p>
<p>My personal goal is to learn to write a Zotero web translator in the webinar, and then write a working web translator for the three biological databases ENA, PDB and Uniprot before the January workshop. And hopefully these activities generate enough interest that other people write web translators for their favorite research data database or software repository, and that the proprietary reference managers Papers and Mendeley (and hopefully others) also add support for these data sources.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Let's do an unconference]]></title>
        <id>03829097-0a63-4baf-b901-ab3d0b84b631</id>
        <link href="https://sensiblescience.io/mfenner/lets-do-an-unconference"/>
        <updated>2014-10-14T15:02:00.000Z</updated>
        <summary type="html"><![CDATA[This year’s SpotOn London conference takes place November 14-15 and the registration has opened this Monday. I am helping organize this conference since 2009, and I again look forward to the sessions, and - more importantly - the discussions with people...]]></summary>
        <content type="html"><![CDATA[<p>This year’s <a href="http://blogs.nature.com/ofschemesandmemes/2014/10/09/how-to-get-a-ticket-for-this-years-spoton-london">SpotOn London conference</a> takes place November 14-15 and the registration has opened this Monday. I am helping organize this conference since 2009, and I again look forward to the sessions, and - more importantly - the discussions with people in and between sessions this year.</p>
<p>The name (ScienceBlogging London, ScienceOnline London, SpotOn London), the location (Royal Institution, British Library, Wellcome Conference Center), the people organizing (too many to mention, but Nature Publishing Group always at the core), and the fringe events (lots of cool things from <a href="http://blog.mendeley.com/academic-life/science-blogging-2008-part-i/">science tours</a> to <a href="http://www.nature.com/spoton/event/spoton-london-2012-fringe-event-the-story-collider-2/">Story Collider</a>) and the format have always changed slightly over the years, and this year again is a bit different. The biggest change is obviously that <a href="https://twitter.com/louwoodley">Lou Woodley</a> is no longer an organizer (as she announced at last year’s conference), but this is also the first SpotOn conference with a theme:</p>
<blockquote>
The challenges of balancing the public and the private in the digital age
</blockquote>
<p>This is obviously a very broad topic, but nicely encompasses many important issues that we are dealing with in scholarly communication today. The draft program is posted <a href="http://blogs.nature.com/ofschemesandmemes/2014/10/13/spoton-london-2014-draft-programme">here</a>, and I’m helping organize the sessions on <strong><strong>sharing sensitive data</strong></strong> and <strong><strong>open peer review</strong></strong>. More details will follow for all these sessions.</p>
<p>The second day of the conference will be in unconference (or barcamp) format and the program drafted by the delegates in the morning. This format is popular in the science communications community (I first heard about the project that became my current job at <a href="https://editor.sensiblescience.io/lets-do-an-unconference/i-was-at-scibarcamp-palo-alto">SciBarCamp in 2009</a>), and SpotOn London has used this format in the first conference in 2008 (and again in 2009):</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/2817131778_336979a571_z.jpg" class="kg-image" alt="Flickr photo by Duncan Hull" /><figcaption aria-hidden="true"><a href="https://www.flickr.com/photos/dullhunk/2817131778/">Flickr photo by Duncan Hull</a></figcaption>
</figure>
<p>For people not familiar with this format the idea of a conference (day) without predetermined topics or speakers sounds scary. As it turns out, the problem is usually not the lack of ideas or people wanting to talk, but rather how to coordinate this in a way that everyone who wants to get involved can do so, and it doesn’t become a discussion among those with the loudest voices (and biggest egos). My experience with SpotOn London and other conferences I enjoyed is that the best sessions are usually those that allow for a good discussion, and not those with the most polished PowerPoint slides. Some suggestions for when you attend an unconference for the first time:</p>
<ul>
<li>go to sessions with topics you know little about, but want to learn more</li>
<li>when suggesting a session, do this together with others</li>
<li>suggest topics that are focussed and unusual, not the obvious ones we always talk about</li>
<li>don’t even think about doing a PowerPoint presentation</li>
<li>when moderating a session, be a good moderator, not a good speaker</li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Science_Foo_Camp">Wikipedia: SciFoo</a></li>
<li><a href="http://blogs.nature.com/nascent/2007/08/barcamb_cambridge.html">Ian Mulvany: BarCamp Cambridge 2007</a></li>
<li><a href="http://science.easternblot.net/?p=613">Eva Amsen: SciBarCamp Toronto 2008</a></li>
<li><a href="https://sensiblescience.io/mfenner/action_points">Me: BibCamp Hannover 2010</a></li>
</ul>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Please keep it simple: citations, links and references]]></title>
        <id>83c6aac6-270c-4c70-97bc-93f1969127c1</id>
        <link href="https://sensiblescience.io/mfenner/please-keep-it-simple-citations-links-and-references"/>
        <updated>2014-10-01T15:06:00.000Z</updated>
        <summary type="html"><![CDATA[In my last post I wrote about the importance of keeping things simple in scholarly publishing, today I want to go into more detail with one example: citations in scholarly documents.LEGO scientists discuss how they can cite their dataCitations are an essential part of scholarly documents,...]]></summary>
        <content type="html"><![CDATA[<p>In my <a href="https://sensiblescience.io/mfenner/please-keep-it-simple/">last post</a> I wrote about the importance of keeping things simple in scholarly publishing, today I want to go into more detail with one example: citations in scholarly documents.</p>
<figure>
<img src="https://editor.sensiblescience.io/content/images/2021/01/lego_discussion.jpg" class="kg-image" srcset="https://editor.sensiblescience.io/content/images/size/w600/2021/01/lego_discussion.jpg 600w, https://editor.sensiblescience.io/content/images/2021/01/lego_discussion.jpg 700w" alt="LEGO scientists discuss how they can cite their data" /><figcaption aria-hidden="true">LEGO scientists discuss how they can cite their data</figcaption>
</figure>
<p>Citations are an essential part of scholarly documents, and they are summarized in the references section at the end of the article or book chapter. The problem is that not everything that is cited in a scholarly document ends up in the references list. Examples of this include:</p>
<ul>
<li>web links, e.g. to reagents or other resources</li>
<li>identifiers for biological databases such as GenBank that are typically included in the text as identifiers or as links</li>
<li>footnotes with links to external resources</li>
</ul>
<p>In other words: we are not consistent in how we cite other content. And this is a problem because we are making it more difficult than necessary for authors, publishers and everyone else to handle these various citation flavors and, more importantly, we are loosing citations along the way. This is a particular problem for data citation, as the seminal 2013 paper by <a href="https://doi.org/10.1371/journal.pone.0063184">Kafkas et al</a>. has shown for citations to the three biological databases ENA (European Nucleotide Archive), PDB and Uniprot:</p>
<ul>
<li>there is a large numbers of accession numbers in the Open Access subset of PubMed Central (e.g. 160,112 ENA accession numbers for papers published up until June 2012)</li>
<li>text mining using the <a href="http://www.ebi.ac.uk/webservices/whatizit/">Whatizit</a> tool can retrieve most of these identifiers</li>
<li>there is only partial overlap between database identifiers annotated by publishers and database identifiers found by text mining</li>
<li>the overlap is even smaller between papers citing database identifiers, and papers cited in biological databases such as ENA</li>
<li>the study was limited to Open Access journals, as only for them the full-text articles could be text mined</li>
</ul>
<figure>
<img src="https://editor.sensiblescience.io/content/images/2021/01/ena_overlap.png" class="kg-image" alt="Comparison between article-to-database and database to citations (Kafkas et al., 2013)." /><figcaption aria-hidden="true">Comparison between article-to-database and database to citations (Kafkas et al., 2013).</figcaption>
</figure>
<p>In other words, even though including identifiers for biological databases has been an accepted community standard that every author and publisher is following for a long time, the proper citation of these identifiers is still often broken. The picture doesn’t seem to be any better for DOIs for datasets: while they are fairly common by now, their use in scholarly articles differs widely from appearance in the references list to links in the materials and methods section to no mention at all.</p>
<p>There are various ways how this can be fixed (e.g. requiring authors to use biological database identifiers in a consistent way, better text mining tools, opening up subscription content to text mining), but the best solution is the simplest one: every citation in a paper should go into the references list. As an example I have added the ENA mRNA U65091 (Shioda, Fenner, &amp; Isselbacher, 1997) - something I worked on a long time ago - to the references list of this post.</p>
<h2 id="technology">Technology</h2>
<p>For this to work, it is essential that reference managers - the software authors use to generate the references list - properly support citations to data, including biological databases. It appears that all major reference managers support datasets as reference type and there is good community agreement what a data citation should look like (<a href="https://www.force11.org/datacitation">Joint Declaration of Data Citation Principles</a>). What is missing is support for easily importing the required metadata for these datasets, and reference managers use two approaches for this:</p>
<ul>
<li>query external databases via API and pull in the required metadata (e.g. Papers, Endnote)</li>
<li>browse to the webpage describing the database entry and import the metadata via bookmarklet/web importer (e.g. Zotero, Mendeley)</li>
</ul>
<p>Both approaches require custom code for every database. Whereas many reference managers use Citation Style Language (<a href="http://citationstyles.org/">CSL</a>) as a standard way to format references, no such standard exists for web importers. Which means that every reference manager has to implement this separately, and most of them are not open source software so that the community could help.</p>
<p>PLOS Labs is holding a <a href="http://www.ploslabs.org/citation-hackathon/">Citation Hackathon</a> on October 18 in their San Francisco office. While I can’t attend in person, I want to contribute to this hackathon in three ways:</p>
<ul>
<li>do an evaluation of how the reference managers Papers, Mendeley and Zotero (the three reference managers I use) support citations to the biological databases ENA, PDB and Uniprot and what is missing</li>
<li>look at existing aggregators of this information (e.g. <a href="http://identifiers.org/">Identifiers.org</a>) to figure out whether the import process can be simplified</li>
<li>start work on Zotero <a href="https://www.zotero.org/support/dev/translators/coding#web_translators">web translators</a> for these three databases. Zotero is open source software and the web translators are written in Javascript</li>
</ul>
<p>Please contact me if you are interested in helping with this, e.g. with a joint virtual hackathon on the 18th (or in person in London or Cambridge on October 15 if that works better).</p>
<p>Together with <a href="https://twitter.com/IanMulvany">Ian Mulvany</a> from eLife and others from Papers and Mendeley we have also submitted a proposal for a pre-conference workshop/hackathon for the <a href="https://www.force11.org/meetings/force2015">Force2015 Conference</a> in January to work on this for a broader set of databases, which should for example also include software repositories. One question is how we properly handle the citation of large numbers of datasets (1000s to millions), we could for example allow a range of identifiers in a citation. We also need tools to convert identifiers and links in existing documents to proper references, something that we <a href="https://sensiblescience.io/mfenner/citations-in-markdown-part-3/">have also discussed on this blog</a>, and we need to discuss how our bibliographic file formats (e.g. bibtex) support these citation types. I <a href="https://sensiblescience.io/mfenner/citeproc-yaml-for-bibliographies/">said before</a> that I am a big fan of Citeproc YAML (or JSON, the bibliographic format used by CSL) as bibliographic exchange format, and I know that the PLOS Labs hackathon will also touch on this.</p>
<h2 id="community">Community</h2>
<p>While adding reference manager support for a wider range of citations is the first step, the bigger challenge is community support. I don’t think that it is a big mental jump for an author to use the reference manager to cite a biological database rather than typing in the identifier directly in the text (the hard work is registering the identifier in the first place), but this needs support by the community, and in particular journal editors. The important message is that citations should be done in a consistent way and authors don’t have to think about doing this differently for datasets or other relevant resources, or different publishers implementing this differently. I think the paper by Kafkas et al. (2013) clearly shows that our current recommendations for adding identifiers to biological databases is broken, and that we need to do something if we take data citation seriously.</p>
<p>There are several concerns about adding every citation to the references list. One of them is that we shouldn’t mix citations of scholarly articles with citations of other things, e.g. research data. I would argue that not only are we seeing an increasing number of <a href="https://doi.org/10.1016/j.ipm.2011.10.002">citations to other resources in reference lists</a>, but that we can of course group citations by citation type, in addition to the sorting by appearance in the text or last name of first author that is common now.</p>
<p>Another concern is that citations of datasets are something else that citations to scholarly articles, because the former are typically citations of content created by the same group of people at the time the journal article was also created. I would argue that again we can highlight this by how we display the references, and that I hope that this changes once data citation becomes more widespread.</p>
<p>What should or should not be cited in a scholarly document is of course a big discussion topic. What I am arguing is that everything that is cited should go into the references list, but that doesn’t change at all what should be cited. Personal communications are an example of something that should probably not be cited and therefore should also not go into the references list.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Please keep it simple]]></title>
        <id>f0e984e7-01d3-4899-b91f-10839b40d68c</id>
        <link href="https://sensiblescience.io/mfenner/please-keep-it-simple"/>
        <updated>2014-09-16T15:08:00.000Z</updated>
        <summary type="html"><![CDATA[Doing scientific research is becoming increasingly complex, both in terms of the tools and technologies used, and in the collaboration across disciplines and locations that is increasingly commonplace. While the way we write up and publish research is of course also very different from 25 years ago,...]]></summary>
        <content type="html"><![CDATA[<p>Doing scientific research is becoming increasingly complex, both in terms of the tools and technologies used, and in the collaboration across disciplines and locations that is increasingly commonplace. While the way we write up and publish research is of course also very different from 25 years ago, I would argue that our tools and services haven’t quite evolved at the same pace.</p>
<p>Of course there are important trends that enable what the Royal Institution <a href="https://royalsociety.org/policy/projects/science-public-enterprise/Report/">calls</a> <em>Science as an Open Enterprise</em>, most importantly Open Access, which has broken down many barriers for open collaboration. But very few organizations - commercial or non-profit - see it as their primary mission to make it easier for researchers to collaborate and produce great science, in the sense that everything else is secondary and this focus is really obvious to everyone.</p>
<p>The following are just some examples that make you laugh hard or cry out loud:</p>
<ul>
<li>Finding relevant scholarly content. Why is still so hard?</li>
<li>Reading a paper. The majority of scholalry content is still not Open Access. It is embarassing how difficult it can be to get the fulltext paper from a subscription journal - too slow, too expensive, and sometimes even crippled in functionality.</li>
<li>Creating figures for publication. This process is still so painful that it hurts. And publishers often create artificial limitations in file type (TIFF or Postscript) and file size (10 MB??).</li>
<li>Licenses for scholarly content. We don’t need choice, but a few licenses that everyone understands and that don’t hinder sharing and collaboration</li>
<li>Secure login. I can use my Facebook or Google login almost everywhere, but as a scholar I have a different username and password at my institution, funder, the various publishers I submit too, and the scholarly services I frequently use?</li>
<li>Citation styles. Why do we still have at least 3,000 styles?</li>
</ul>
<p>Citation styles is a perfect example of a problem that should have been solved as soon as we made the switch to digital publishing. I can travel through half of Europe without showing my passport, and using the same currency, but I need to reformat citations every time I submit to a different journal? And I have to use the same tool for this as my coauthors, as the different reference managers don’t work with each other?</p>
<p>Too often there are other intentions at work in parallel. While notable, they sometimes stand in conflict with the goal of making a researcher’s life easier. A perfect example is the manuscript submission process. In parallel to the tools getting better and easier to use, the demands on the author seem to be increasing at an even greater rate, both in the data and metadata he or she should provide, and in the work submitting authors are asked to do that traditionally have been done by publishers. Another good example are peer review and evaluation. The proportion of time spent doing research vs. time spent doing administrative work seems to decreasing and not increasing.</p>
<p>I wish more people and organizations would stand up and state that keeping it simple is their primary goal.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CommonMark and the Future of Scholarly Markdown]]></title>
        <id>3acc3fd3-5b94-4486-a9a7-55b578384046</id>
        <link href="https://sensiblescience.io/mfenner/commonmark-and-the-future-of-scholarly-markdown"/>
        <updated>2014-09-07T15:10:00.000Z</updated>
        <summary type="html"><![CDATA[One of the important outcomes of the Markdown for Science workshop that took place in June 2013 was a decision on a name - <em>Scholarly Markdown</em> - and a brief definition:Markdown that supports the requirements of scientific textsMarkdown as format...]]></summary>
        <content type="html"><![CDATA[<p>One of the important outcomes of the <a href="https://github.com/scholmd/scholmd/wiki">Markdown for Science</a> workshop that took place in June 2013 was a decision on a name - <em>Scholarly Markdown</em> - and a brief <a href="https://github.com/scholmd/scholmd/wiki/What-is-Markdown">definition</a>:</p>
<ol>
<li>Markdown that supports the requirements of scientific texts</li>
<li>Markdown as format that glues open scientific text resources together</li>
<li>A reference implementation with documentation and tests</li>
<li>A community</li>
</ol>
<p>In my eyes this is still a great definition. And this week something important happened that is very relevant for Scholarly Markdown. A small group of people deeply involved in Markdown announced <a href="http://commonmark.org/">Standard Markdown</a>:</p>
<blockquote>
We propose a standard, unambiguous syntax specification for Markdown, along with a suite of comprehensive tests to validate Markdown implementations against this specification. We believe this is necessary, even essential, for the future of Markdown.
</blockquote>
<p>Markdown is in widespread use, but a lack of standard syntax and set of comprehensive tests has hindered the adoption for more complex use cases, the development of cross-platform tools, and the use of markdown as a document interchange format. I am therefore 100% behind this initiative. In particular since this is not just an initiative by large commercial organizations heavily using Markdown such as Stack Exchange, Github or Reddit, but that the entire spec and both reference implementations have been written by <a href="http://johnmacfarlane.net/">John MacFarlane</a>, the author of Pandoc, the universal document converter. Not only does Pandoc already support many of the features required by Scholarly Markdown (e.g. math and citations), but John is the Chair of the Department of Philosophy at UC Berkeley.</p>
<p>Markdown was developed in 2004 by John Gruber, and he <a href="http://daringfireball.net/projects/markdown/license">holds the rights</a> to the name Markdown. He didn’t want this initiative to use the name <strong><strong>Standard Markdown</strong></strong>, so the implementation was <a href="http://blog.codinghorror.com/standard-markdown-is-now-common-markdown/">renamed</a> to <a href="http://commonmark.org/">CommonMark</a>.</p>
<p>The consequences of all this for Scholarly Markdown?</p>
<ul>
<li>CommonMark focusses on the basic features of the language, but once the specification is agreed upon and implemented by a critical mass of tools, it is clear that there needs to be a standardized way to handle extensions of the language. This is both about features used by lots of people such as tables, but also functionality relevant only for scholarly content.</li>
<li>This brings us one gigantic step closer to a reference implementation and set of tests for Scholarly Markdown, as hopefully Scholarly Markdown can build upon the work by John and the CommonMark team.</li>
<li>The name Scholarly Markdown might not be a good idea going forward. We should either change the name to align with CommonMark, or we should come up with a totally different name, something that the screenwriters have done with <a href="http://fountain.io/">their</a> implementation of Markdown.</li>
</ul>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using Microsoft Word with git]]></title>
        <id>dcb09e05-e221-4a23-9567-3e72ce02716c</id>
        <link href="https://sensiblescience.io/mfenner/using-microsoft-word-with-git"/>
        <updated>2014-08-25T15:12:00.000Z</updated>
        <summary type="html"><![CDATA[One of the major challenges of writing a journal article is to keep track of versions - both the different versions you create as the document progresses, and to merge in the changes made by your collaborators. For most academics Microsoft Word is the default writing tool,...]]></summary>
        <content type="html"><![CDATA[<p>One of the major challenges of writing a journal article is to keep track of versions - both the different versions you create as the document progresses, and to merge in the changes made by your collaborators. For most academics Microsoft Word is the default writing tool, and it is both very good and very bad in this. Very good because the <em>track changes</em> feature makes it easy to see what has changed since the last version and who made the changes. Very bad because this feature is built around keeping everything in a single Word document, so that only one person can work on on a manuscript at a time. This usually means sending manuscripts around by email, and being very careful about not confusing different versions of the document, which requires <a href="http://www.phdcomics.com/comics/archive.php?comicid=1531">creativity</a>.</p>
<p>Approaches to overcome these challenges are to a) integrate the Word documents into collaboration tools such as Sharepoint and Office 365, or document sharing services such as Dropbox and Google Docs (if you use it just for that), or b) use a different authoring tool altogether. If neither of these approaches works for you, you have a third option: use the version control system <strong><strong>git</strong></strong>.</p>
<p><a href="http://www.mulvany.net/presentations/WikimaniaOpenScholarshipTalk.slides.html#/3">Git</a> is software that helps with <a href="https://git-scm.com/book/en/Getting-Started-About-Version-Control">tracking changes to files</a> so that you can recall specific versions later. Git is typically used to track changes of software source code (and was originally developed by Linus Torvalds for Linux kernel development in 2005), but in fact git can be used for any file where we need to keep track of versions over time. Git is open source software that runs locally on your computer, so please go ahead and start tracking changes to your manuscripts (or other complex documents) with git. Any time you want to store a version, do a <code>git commit</code> with a little description and an optional tag.</p>
<p>This approach is not ideal, as git was written with source code in text format in mind and for example doesn’t understand what has changed between two revisions of a Word document. Some people will tell you to never store binary files in a version control system, but don’t listen to them. Instead give git a tool to convert Word documents into plain text, and git will then happily tell you what has changed between revisions. Several tools can do this, but since earlier this month Pandoc can read Word documents in <code>docx</code> format. Do the following to have Pandoc convert Word documents into markdown, and to compare the revisions by word and not by line (which makes more sense):</p>
<pre><code># .gitattributes file in root folder of your git project
*.docx diff=pandoc</code></pre>
<pre><code># .gitconfig file in your home folder
[diff &quot;pandoc&quot;]
  textconv=pandoc --to=markdown
  prompt = false
[alias]
  wdiff = diff --word-diff=color --unified=1</code></pre>
<p>You can then use <code>git wdiff important_file.docx</code> to see the changes (with deletions in red and insertions in green), or <code>git log -p --word-diff=color important_file.docx</code> to see all changes over time.</p>
<p>While you can now track revisions of a Word document and see the changes, you also want to be able to merge different versions of a Word document together so that you and your collaborators can work on the manuscript in parallel. Git can’t merge binary files together, so you need to first convert the Word document into a format that git understands. Just as in the previous example we can use Pandoc for that, with markdown as the textual format. This would also work with HTML or LaTeX, but the simplicity of markdown makes it better suited for version control which doesn’t know about the markup of these formats.</p>
<p>One of the reasons that git became so popular with software developers is that it is a <strong><strong>distributed version control system</strong></strong> instead of a centralized system such as Subversion. This means that you can track all revisions locally on your computer, but can still synchronize your revisions with another user. <strong><strong>Github</strong></strong> is a popular service that facilitates this synchronization and adds some nice features on top. One way to collaborate with your co-authors is therefore to set up a Github repository (public or private) for your manuscript, and store the master version of the manuscript in markdown format. Instead of working on the master version directly, you would use Pandoc to convert back and forth between this master version in markdown format and your Word document, and would continue to use Word as authoring tool. <a href="https://sensiblescience.io/mfenner/introducing-rakali/">Rakali</a> is a Pandoc tool that I released last week that can help automate this document conversion. Github has a a number of features to facilitate collaboration that can be used here, e.g. Github issues for discussion and task management.</p>
<p>There are still a few rough edges in the workflow described above (e.g. only partial support of Word track changes), but it is an interesting approach to collaborate using Microsoft Word and git. And this workflow can of course be enhanced to also include authors that write in LaTeX or one of the other formats that Pandoc supports. One nice side effect of using markdown is that Github will automatically render a webpage for the document (which it will not do for HTML without extra effort).</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing Rakali]]></title>
        <id>6d23947a-61d8-40c4-b020-51ba50dac3d1</id>
        <link href="https://sensiblescience.io/mfenner/introducing-rakali"/>
        <updated>2014-08-18T15:16:00.000Z</updated>
        <summary type="html"><![CDATA[In July and August I attended the Open Knowledge Festival and Wikimania. At both events I had many interesting discussions around open source tools for open access scholarly publishing, and I was part of a panel on that topic at Wikimania last Sunday....]]></summary>
        <content type="html"><![CDATA[<p>In July and August I attended the <a href="http://2014.okfestival.org/">Open Knowledge Festival</a> and <a href="http://wikimania2014.wikimedia.org/wiki/Programme">Wikimania</a>. At both events I had many interesting discussions around open source tools for open access scholarly publishing, and I was part of a <a href="http://wikimania2014.wikimedia.org/wiki/Submissions/The_Full_OA_Stack_-_Open_Access_and_Open_Source">panel</a> on that topic at Wikimania last Sunday. Some of my thoughts were summarized in a blog post a few weeks ago (<a href="https://sensiblescience.io/mfenner/roads-not-stagecoaches/">Build Roads not Stagecoaches</a>). Today I am happy to announce the first public release of a tool that hopefully contributes to making publishing of open content a bit easier.</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/rakali.jpg" class="kg-image" alt="LEGO Researchers are excited that they don’t have to use Microsoft Word for manuscript writing anymore." /><figcaption aria-hidden="true">LEGO Researchers are excited that they don’t have to use Microsoft Word for manuscript writing anymore.</figcaption>
</figure>
<p><a href="https://github.com/rakali/rakali.rb">Rakali</a> is a Ruby gem that acts as a wrapper for the <a href="https://pandoc.org">Pandoc</a> universal document converter. Pandoc is a wonderful tool to convert documents between file formats and supports many file formats and features important for scholarly publishing. Pandoc 1.13 was <a href="http://johnmacfarlane.net/pandoc/releases.html">released</a> last Friday, and one of the most exciting new features is a reader for Microsoft Word (<code>docx</code>) documents. Pandoc has supported the conversion to <code>docx</code> for a while, but now you can use the most popular file format for writing scholarly documents and turn your <code>docx</code> files into HTML, PDF, LateX, markdown, or a number of other formats, making it much easier to collaborate, and to use <code>docx</code> with Pandoc in scholarly publishing workflows. A good example would be arXiv, which <a href="http://arxiv.org/help/submit#text">doesn’t support</a> <code>docx</code> for text submissions. Instead of turning it into PDF the manuscript can now be converted to LaTeX - the preferred file format at arXiv - before submission.</p>
<p>I built <strong><strong>Rakali</strong></strong> to make it easier to use Pandoc to convert large numbers of documents in an automated way:</p>
<ul>
<li>bulk conversion of all files in a folder with a specific extension, e.g. <code>md</code>.</li>
<li>input via a configuration file in yaml format instead of via the command line</li>
<li>validation of documents via <a href="http://json-schema.org/">JSON Schema</a>, using the <a href="https://github.com/hoxworth/json-schema">json-schema</a> Ruby gem.</li>
<li>Logging via <code>stdout</code> and <code>stderr</code>.</li>
</ul>
<p>One interesting way to use Rakali and Pandoc is as part of a <a href="https://sensiblescience.io/mfenner/continuous-publishing/">continuous publishing</a> workflow that involves git and Github, automatically converting all files in a folder when something is pushed to the repository using a continuous integration tool, and exiting the continuous integration run when one of the files doesn’t validate. Look into the Rakali <a href="https://github.com/rakali/rakali.rb">repo</a> for an example.</p>
<p>The most interesting aspect of Rakali is probably validation via JSON Schema. File conversion with Pandoc is a two-step process, the intermediate format is an internal representation of the document in something called the <a href="https://sensiblescience.io/mfenner/the-grammar-of-scholarly-communication/">abstract syntax tree</a> or AST. Pandoc makes the AST accessible in JSON format, making it straightforward to manipulate a document before the conversion into the target format with something called <a href="http://johnmacfarlane.net/pandoc/scripting.html">JSON filters</a>.</p>
<p>Validation of XML documents using <a href="https://en.wikipedia.org/wiki/Document_type_definition">DTDs</a>, <a href="http://relaxng.org/">RELAX NG</a> and other standards has of course been around for a long time, but validation of JSON documents is still relatively new. Since many Pandoc document conversion workflows don’t involve any XML I thought it would make more sense to validate against the AST, and we can use JSON Schema for that. I have started a <a href="https://github.com/rakali/pandoc-schemata">Github repository</a> with schemata for the Pandoc AST, and hope to evolve them over time using Rakali as a tool. An example log output (from the Rakali test suite, stopping file conversion because title and layout metadata are missing) looks like this:</p>
<pre><code>Validation Error: The property &#39;#/0/unMeta&#39; did not contain a required property of &#39;title&#39; in schema 9b6d454d-e609-537b-b761-9599b6c01072# for file empty.md
Validation Error: The property &#39;#/0/unMeta&#39; did not contain a required property of &#39;layout&#39; in schema 9b6d454d-e609-537b-b761-9599b6c01072# for file empty.md
Fatal: Conversion of file empty.md failed.</code></pre>
<p>As I had argued before, the challenge for building open source tools for science is to <a href="https://sensiblescience.io/mfenner/dont-reinvent-the-wheel/">not duplicate the work of others</a>, and to integrate well with existing tools by focussing on one aspect and doing that aspect well. It also helps to think about infrastructure (<a href="https://sensiblescience.io/mfenner/roads-not-stagecoaches/">the roads</a>) instead of only focussing on the user-facing aspects. There are obviously many document conversion tools out there, but Pandoc is certainly one of the oldest and most established ones for scholarly content. Rakali therefore builds on top of Pandoc and tries to play well with other existing tools and services, e.g. by using the UNIX <code>stdout</code> and <code>stderr</code> for reporting, and by using a file-based approach that works well with version control systems such as git. And since Rakali is a Ruby gem it can not only be used as a standalone command line tool, but can also be easily integrated into other Ruby applications.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visualizing Scholarly Content]]></title>
        <id>cb59dc57-e557-438a-b87d-1d0a26b06fa1</id>
        <link href="https://sensiblescience.io/mfenner/visualizing-scholarly-content"/>
        <updated>2014-08-09T15:19:00.000Z</updated>
        <summary type="html"><![CDATA[One topic I will cover this Sunday in a presentation on Open Scholarship Tools at <em>Wikimania 2014</em> together with Ian Mulvany is visualization.Data visualization is all about <em>telling stories with data</em>, something that is of course not only important for scholarly content,...]]></summary>
        <content type="html"><![CDATA[<p>One topic I will cover this Sunday in a presentation on <a href="http://wikimania2014.wikimedia.org/wiki/Submissions/Open_Scholarship_Tools_-_a_whirlwind_tour.">Open Scholarship Tools</a> at <em>Wikimania 2014</em> together with <a href="https://twitter.com/ianmulvany">Ian Mulvany</a> is visualization.</p>
<p>Data visualization is all about <em>telling stories with data</em>, something that is of course not only important for scholarly content, but for example increasingly common in journalism. This is a big and complex topic, but I hope the following will get you started.</p>
<h3 id="learn-the-basics">Learn the Basics</h3>
<p>Work on visualization of scientific data should start with a good understanding of the best practices and pitfalls of data visualization in general, as well as the specific aspects of visualizing scientific data. The following resources have helped me get started - please suggest more in the comments:</p>
<ul>
<li><a href="http://book.flowingdata.com/">Visualize this</a>. A book from Nathan Yau published in 2011. Very helpful in understanding the different ways data can be visualized (e.g. when to use a treemap or what is a <a href="https://en.wikipedia.org/wiki/Choropleth_map">chloropleth map</a>), and an introduction to some tools using practical examples. Nathan’s <a href="http://flowingdata.com/">FlowingData</a> blog is also a great resource.</li>
<li><a href="https://github.com/mbostock/d3/wiki/Gallery">D3 Gallery</a>. Lots of examples generated using Mike Bostock’s d3.js visualization library. A great inspiration for data visualization on the web, even if you use a different visualization tool.</li>
<li><a href="http://docs.ggplot2.org/current/index.html">ggplot2</a>. Not only a very popular visualization library for the R language by Hadley Wickham, but also an implementation of Leland Wilkison’s Grammar of Graphics. The <a href="http://www.springer.com/statistics/computational+statistics/book/978-0-387-98140-6">ggplot2 book</a> describes this powerful concept (p. 14):</li>
</ul>
<blockquote>
In brief, the grammar tells us that a statistical graphic is a mapping from data to aesthetic attributes (colour, shape, size) of geometric objects (points, lines, bars). The plot may also contain statistical transformations of the data and is drawn on a specific coordinate system. Faceting can be used to generate the same plot for different subsets of the dataset. It is the combination of these independent components that make up a graphic.
</blockquote>
<h3 id="learn-to-use-at-least-one-visualization-tool">Learn to use at least one visualization tool</h3>
<p>There are many great tools available, pick one and learn it well. Some options include:</p>
<ul>
<li><strong><strong>Excel</strong></strong>. Probably the most popular tool for data visualization. Commercial, with open source alternatives such as Libre Office.</li>
<li><strong><strong>R</strong></strong>. Software for statistical computing and analysis. Open source. <a href="http://www.rstudio.com/">RStudio</a> is a powerful user interface for R and a good way to get started.</li>
<li><a href="http://d3js.org/"><strong>d3.js</strong></a>. A visualization library for Javascript. Open source.</li>
<li><a href="http://www.graphpad.com/scientific-software/prism/"><strong>Prism</strong></a>. A popular visualization tool among scientists. Commercial.</li>
<li><a href="https://datawrapper.de/"><strong>Datawrapper</strong></a>. An open source tool and hosted service for data visualization.</li>
</ul>
<p>I do most visualizations in either R or d3.js. Both are open source tools with a large community and a rich set of libraries, examples and documentation, and both take a systematic approach to data visualization (see grammar of graphics above).</p>
<h3 id="learn-data-analysis">Learn data analysis</h3>
<p>Unless your interest is more in information design - see <a href="http://www.informationisbeautiful.net/">Information is beautiful</a> for some great examples - data visualization is tightly coupled with data analysis. You need to know at least the basics of data analysis to do proper data visualizations, e.g. how to handle wrongly formatted data (e.g. text in a number column), missing values and outliers. The most time-consuming step in my experience is data transformation, i.e. bringing data into the format that you want for the analysis and visualization.</p>
<p>R, Python and the relatively new <a href="http://julialang.org/">Julia</a> are popular languages for data analysis available as open source. There are many packages for these languages that help with common data analysis problems. One additional advantage of using a proper language over a set of tools cobbled together is that it is easy to automatically recreate a visualization with a new set of data - convenient when you need to analyze and visualize an ongoing experiment that repeatedly produces new data.</p>
<h3 id="use-a-vector-file-format">Use a vector file format</h3>
<p>Too many scientific data are still visualized using bitmap graphic formats such as <code>tiff</code>, <code>jpg</code> and <code>png</code>. These formats are not appropriate for charts and only make sense for images. They don’t scale to the screen resolution, and it is <a href="http://blog.f1000research.com/2014/02/20/the-importance-of-providing-data-and-not-just-images-of-data/">very hard to impossible</a> to reuse or even modify them. Use vector graphic formats such as <code>svg</code> or <code>pdf</code> instead. <code>svg</code> is my preferred format because in contrast to <code>pdf</code> it can be embedded into a larger HTML document, and R and d3.js (my preferred visualization tools) can generate this format. <a href="http://www.inkscape.org/">Inkscape</a> is an open source SVG editor, and the commercial <strong><strong>Adobe Illustrator</strong></strong> can be used to manually polish graphics in <code>svg</code> or <code>pdf</code> format, e.g. for journal publication.</p>
<h3 id="get-inspired-by-great-visualizations">Get inspired by great visualizations</h3>
<p>At the end of the day data visualization is all about telling a story with data. Unfortunately the current state of affairs for scientific visualizations is very different. In my opinion most graphs and figures used in publications don’t provide the data underlying the visualization (<a href="https://datawrapper.de/">Datawrapper</a> is a great example how this can be done), focus too much on detail rather than the overall message, don’t take advantage of the different chart types available, and are sometimes even misleading. And I’m not even talking about the fact that figures in scholarly papers are <a href="https://doi.org/10.12688/f1000research.4263.1">almost never</a> interactive. It rarely happens that I read a paper and get excited by looking at a figure - if I do it is usually because the underlying data are so compelling that even the simplest visualization will convey the right message.</p>
<p>We should become more creative with visualizing data in scholarly documents, and one important step towards that goal is publishers accepting more reasonable file formats in manuscript submissions - instead of just <code>tiff</code> and <code>eps</code> (<a href="http://www.plosone.org/static/figureGuidelines#figures">PLOS</a>), or <code>tiff</code>, <code>eps</code> and <code>pdf</code> (<a href="http://www.sciencemag.org/site/feature/contribinfo/prep/prep_revfigs.xhtml#format">Science</a>), and often with a 10 MB file site limit.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is a DOI?]]></title>
        <id>2caa27fe-c069-41a0-bed2-931ab552c163</id>
        <link href="https://sensiblescience.io/mfenner/what-is-doi"/>
        <updated>2014-08-06T15:24:00.000Z</updated>
        <summary type="html"><![CDATA[This Sunday Ian Mulvany and I will do a presentation on Open Scholarship Tools at <em>Wikimania 2014</em> in London. From the abstract:This presentation will give a broad overview of tools and standards that are helping with Open Scholarship today.One...]]></summary>
        <content type="html"><![CDATA[<p>This Sunday <a href="https://twitter.com/ianmulvany">Ian Mulvany</a> and I will do a presentation on <a href="http://wikimania2014.wikimedia.org/wiki/Submissions/Open_Scholarship_Tools_-_a_whirlwind_tour.">Open Scholarship Tools</a> at <em>Wikimania 2014</em> in London. From the abstract:</p>
<blockquote>
This presentation will give a broad overview of tools and standards that are helping with Open Scholarship today.
</blockquote>
<p>One of the four broad topics we have picked are <em>digital object identifiers (DOI)s</em>. We want to introduce them to people new to them, and we want to show some tricks and cool things to people who already now them. Along the way we will also try to debunk some myths about DOIs.</p>
<h3 id="what-a-doi-looks-like">What a DOI looks like</h3>
<p>DOIs - or better DOI names - start with a prefix in the format <code>10.x</code> where x is 4-5 digits. The suffix is determined by the organization registering the DOI, and there is no consistent pattern across organizations. The DOI name is typically expressed as a URL (see below). An example DOI would look like: <a href="http://dx.doi.org/10.5555/12345678">http://dx.doi.org/10.5555/12345678</a>. Something in the format <strong><strong>10/hvx</strong></strong> or <a href="http://doi.org/hvx">http://doi.org/hvx</a> is a <a href="http://shortdoi.org/">shortDOI</a>, and <strong><strong>1721.1/26698</strong></strong> or <a href="http://hdl.handle.net/1721.1/26698">http://hdl.handle.net/1721.1/26698</a> is a handle. BTW, all DOIs names are also handles, so <a href="http://hdl.handle.net/10/hvx">http://hdl.handle.net/10/hvx</a> for the shortDOI example above will resolve correctly.</p>
<h3 id="dois-are-persistent-identifiers">DOIs are persistent identifiers</h3>
<p>Links to resources can change, particularly over long periods of time. Persistent identifiers are needed so that readers can still find the content we reference in a scholarly work (or anything else where persistent linking is important) 10 or 50 years later. There are many kinds of persistent identifiers, one of the key concepts - and a major difference to URLs - is to separate the identifier for the resource from its location. Persistent identifiers require technical infrastructure to resolve identifiers (DOIs use the <a href="http://www.handle.net/">Handle System</a>) and to allow long-term archiving of resources. DOI registration agencies such as DataCite or CrossRef are required to provide that persistence. Other persistent identifier schemes besides DOIs include <a href="http://en.wikipedia.org/wiki/PURL">persistent uniform resource locators (PURLs)</a> and <a href="http://en.wikipedia.org/wiki/Archival_Resource_Key">Archival Resource Keys (ARKs)</a>.</p>
<h3 id="dois-have-attached-metadata">DOIs have attached metadata</h3>
<p>All DOIs have metadata attached to them. The metadata are supplied by the resource provider, e.g. publisher, and exposed in services run by registration agencies, for example metadata search and content negotiation (see below). There is a minimal set of required metadata for every DOI, but beyond that, different registration agencies will use different metadata schemata, and most metadata are optional. Metadata are important to build centralized discovery services, making it easier to describe a resource, e.g. journal article citing another article. Some of the more recent additions to metadata schemata include persistent identifiers for people (<a href="http://orcid.org/">ORCID</a>) and funding agencies (<a href="http://www.crossref.org/fundref/">FundRef</a>), and license information. The following API call will retrieve all publications registered with CrossRef that use a <a href="http://creativecommons.org/licenses/by/3.0/deed.en_US">Creative Commons Attribution license</a> (and where this information has been provided by the publisher):</p>
<pre><code>http://api.crossref.org/funders/10.13039/100000001/works?filter=license.url:http://creativecommons.org/licenses/by/3.0/deed.en_US</code></pre>
<h3 id="dois-support-link-tracking">DOIs support link tracking</h3>
<p>Links to other resources are an important part of the metadata, and describing all citations between a large number scholarly documents is a task that can only really be accomplished by a central resource. To solve this very problem DOIs were invented and the CrossRef organization started around 15 years ago.</p>
<h3 id="not-every-doi-is-the-same">Not every DOI is the same</h3>
<p>The DOI system <a href="http://www.doi.org/doi_handbook/1_Introduction.html">originated from an initiative by scholarly publishers</a> (first announced at the Frankfurt Book Fair in 1997), with citation linking of journal articles its first application. This citation linking system is managed by <a href="http://www.crossref.org/">CrossRef</a>, a non-profit member organization of scholarly publishers, and <a href="http://search.crossref.org/help/status">more than half</a> of the about <a href="http://www.doi.org/faq.html">100 million DOIs</a> that have been assigned to date are managed by them.</p>
<p>But many DOIs are assigned by one of the other 8 <a href="http://www.doi.org/RA_Coverage.html">registration agencies</a>. You probably know <a href="http://www.datacite.org/">DataCite</a>, but did you know that the <a href="http://publications.europa.eu/index_en.htm">Publications Office of the European Union (OP)</a> and the <a href="http://www.eidr.org/">Entertainment Identifier Registry (EIDR)</a> also assign DOIs? The distinction is important, because some of the functionality is a service of the registration agency - metadata search for example is offered by CrossRef (<a href="http://search.crossref.org/">http://search.crossref.org</a>) and DataCite (<a href="http://search.datacite.org/">http://search.datacite.org</a>), but you can’t search for a DataCite DOI in the CrossRef metadata search. There is an API to find out the registration agency behind a DOI so that you know what services to expect:</p>
<pre><code>http://api.crossref.org/works/10.6084/m9.figshare.821213/agency

{
  &quot;status&quot;: &quot;ok&quot;,
  &quot;message-type&quot;: &quot;work-agency&quot;,
  &quot;message-version&quot;: &quot;1.0.0&quot;,
  &quot;message&quot;: {
    &quot;DOI&quot;: &quot;10.6084/m9.figshare.821213&quot;,
    &quot;agency&quot;: {
      &quot;id&quot;: &quot;datacite&quot;,
      &quot;label&quot;: &quot;DataCite&quot;
    }
  }
}</code></pre>
<h3 id="dois-are-urls">DOIs are URLs</h3>
<p><a href="http://www.doi.org/faq.html">DOI names may be expressed as URLs (URIs) through a HTTP proxy server</a> - e.g. <a href="http://dx.doi.org/10.5555/12345679">http://dx.doi.org/10.5555/12345679</a>, and this is how DOIs are typically resolved. For this reason the <a href="http://www.crossref.org/02publishers/doi_display_guidelines.htm">CrossRef DOI Display Guidelines</a> recommend that <em>CrossRef DOIs should always be displayed as permanent URLs in the online environment</em>. Because DOIs can be expressed as URLs, they also have their features:</p>
<h4 id="special-characters">Special characters</h4>
<p>Because DOIs can be expressed as URLs, DOIs <a href="http://www.crossref.org/02publishers/15doi_guidelines.html">should only include characters allowed in URLs</a>, something that wasn’t always true in the past and can cause problems, e.g. when using SICIs (<a href="https://en.wikipedia.org/wiki/Serial_Item_and_Contribution_Identifier">Serial Item and Contribution Identifier</a>), an extension of the ISSN for journals:</p>
<pre><code>10.4567/0361-9230(1997)42:&lt;OaEoSR&gt;2.0.TX;2-B</code></pre>
<h4 id="content-negotiation">Content negotiation</h4>
<p>The DOI resolver at <em>doi.org</em> (or <em>dx.doi.org</em>) normally resolves to the resource location, e.g. a landing page at a publisher website. Requests that are not for content type <code>text/html</code> are redirected to the registration agency metadata service (currently for CrossRef, DataCite and mEDRA DOIs). Using <a href="http://www.crosscite.org/cn/">content negotiation</a>, we can ask the metadata service to send us the metadata in a format we specify (e.g. Citeproc JSON, bibtex or even a formatted citation in one of thousands of citation styles) instead of getting redirected to the resource. This is a great way to collect bibliographic information, e.g. to format citations for a manuscript. In theory we could also use content negotiation to get a particular representation of a resource, e.g. <code>application/pdf</code> for a PDF of a paper or <code>text/csv</code> for a dataset in CSV format. This is not widely support and I don’t know the details of the implementation in the DOI resolver, but you can try this (content negotation is easier with the command line than with a browser):</p>
<pre><code>curl -LH &quot;Accept: application/pdf&quot; http://dx.doi.org/10.7717/peerj.500 &gt;peerj.500.pdf</code></pre>
<p>This will save the PDF of the 500th PeerJ paper published last week.</p>
<h4 id="fragment-identifiers">Fragment identifiers</h4>
<p>As discussed in <a href="http://sensiblescience.io/mfenner/fragment-identifiers-and-dois/">my last blog post</a>, we can use fragment identifiers to subsections of a document with DOIs, e.g. <a href="http://dx.doi.org/10.1371/journal.pone.0103437#s2">http://dx.doi.org/10.1371/journal.pone.0103437#s2</a> or <a href="http://doi.org/10.5446/12780#t=00:20,00:27">http://doi.org/10.5446/12780#t=00:20,00:27</a>, just as we can with every other URL. This is a nice way to directly link to a specific document section, e.g. when discussing a paper on Twitter. Fragment identifiers are implemented by the client (typically web browser) and depend on the document type, but for DOIs that resolve to full-text HTML documents they can add granularity to the DOI without much effort.</p>
<h4 id="queries">Queries</h4>
<p>URLs obviously support queries, but that is a feature I haven’t yet seen with DOIs. Queries would allow interesting features, partly overlapping with what is possible with fragment identifiers and content negotiation, e.g. <code>http://dx.doi.org/10.7717/peerj.500?format=pdf</code>. II hope to find out more until Sunday.</p>
<h3 id="outlook">Outlook</h3>
<p>My biggest wish? Make DOIs more machine-readable. They are primarily intended for human users, enabling them to find the content associated with a DOI. But they sometimes don’t work as well as they could with automated tools, one example are the <a href="http://sensiblescience.io/mfenner/broken-dois/">challenges automatically resolving a DOI</a> that I described in a blog post last year. Thinking about DOIs as URLs - and using them this way - is the right direction.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fragment Identifiers and DOIs]]></title>
        <id>33c7abb9-7959-4fcf-9368-56882a8d5076</id>
        <link href="https://sensiblescience.io/mfenner/fragment-identifiers-and-dois"/>
        <updated>2014-08-02T15:26:00.000Z</updated>
        <summary type="html"><![CDATA[Before all our content turned digital, we already used <strong><strong>page numbers</strong></strong> to describe a specific section of a book or longer document, with older manuscripts using the folio before that....]]></summary>
        <content type="html"><![CDATA[<p>Before all our content turned digital, we already used <strong><strong>page numbers</strong></strong> to describe a specific section of a book or longer document, with older manuscripts using the <a href="https://en.wikipedia.org/wiki/Folio">folio</a> before that. Page numbers have transitioned to electronic books with readers such as the Kindle <a href="http://pogue.blogs.nytimes.com/2011/02/08/page-numbers-for-kindle-books-an-imperfect-solution/?_php=true&amp;_type=blogs&amp;_r=0">supporting them eventually</a>.</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/12th/Folio_(number).jpg" class="kg-image" alt="Image by Al Silonov from Wikimedia Commons. This file is licensed under the Creative Commons Attribution-Share Alike 3.0 Unported license." /><figcaption aria-hidden="true">Image by Al Silonov from <a href="http://commons.wikimedia.org/wiki/File:Folio_(number).jpg">Wikimedia Commons</a>. This file is licensed under the <a href="http://creativecommons.org/licenses/by-sa/3.0/deed.en">Creative Commons Attribution-Share Alike 3.0 Unported</a> license.</figcaption>
</figure>
<p>For content on the web we can use the <code>#</code> fragment identifier, e.g. <a href="https://en.wikipedia.org/wiki/Fragment_identifier#Proposals">https://en.wikipedia.org/wiki/Fragment_identifier#Proposals</a> to navigate to a specific section of a web page. How the linking to this fragment is handled, depends on the <strong><strong>MIME</strong></strong> type of the document, and will for example be done differently for a text page than a video - YouTube understands minutes and seconds into a video as fragment identifier, e.g. <a href="https://www.youtube.com/watch?v=0UNRZEsLxKc#t=54m52s">https://www.youtube.com/watch?v=0UNRZEsLxKc#t=54m52s</a>. Fragment identifiers are not only helpful to link to a subsection of a document, but of course also for navigation within a document.</p>
<p>All this is of course very relevant to scholarly content, which is usually much more structured, with most journal articles following the <a href="https://en.wikipedia.org/wiki/IMRAD">IMRAD</a> - introduction, methods, results, and discussion - format, usually with additional sections such as abstract, references, etc. One approach to link to figures and tables within a scholarly articles is using <a href="https://blog.martinfenner.org/posts/direct-links-to-figures-and-tables-using-component-dois/">component DOIs</a>, e.g. specific DOIs for parts of a larger document. The publisher <strong><strong>PLOS</strong></strong> has been using them for a long time, and the <a href="https://editor.sensiblescience.io/2014/07/24/dont-reinvent-the-wheel/">number of component DOIs is rising</a>, but most scholarly journal articles don’t use component DOIs. And whereas component DOIs are a great concept for content such as figures (allowing us to describe the MIME type and other relevant metadata), they are probably not the best tool to link to a section or paragraph of a scholarly document.</p>
<p>As it turns out, we already have a tool for that, as the DOI proxy server gracefully forwards fragment identifiers (how did I miss this?). We can therefore use a DOI with a fragment identifier to</p>
<ul>
<li>Results section: <a href="https://doi.org/10.1371/journal.pone.0103437#s2">http://doi.org/10.1371/journal.pone.0103437#s2</a></li>
<li>Specific reference: <a href="https://doi.org/10.12688/f1000research.4263.1#ref-7">http://doi.org/10.12688/f1000research.4263.1#ref-7</a></li>
<li>Decision letter: <a href="https://doi.org/10.7554/eLife.00471#decision-letter">http://doi.org/10.7554/eLife.00471#decision-letter</a></li>
</ul>
<p>Obviously this only works if the DOI is resolved to the full-text of a resource, and not a landing page. And how the fragment identifiers are named and implemented is up to the publisher, and the DOI resolver has no information about them. These specific links are particularly nice for discussions of a paper, whether it is on Twitter or in a discussion forum. It appears that at least the Twitter link shortener keeps the fragment identifier, the link to the eLife decision letter is shortened to <a href="http://t.co/URWaYmGHnY">http://t.co/URWaYmGHnY</a>. This kind of linking works particularly well if the publisher is using a fine-grained system of fragment identifiers, the publisher PeerJ for example allows links to a specific paragraph - e.g. <a href="http://doi.org/10.7717/peerj.500#p-15">http://doi.org/10.7717/peerj.500#p-15</a> - and allows users to <a href="http://blog.peerj.com/post/62886292466/peerj-questions-a-new-way-to-never-publish-forget">ask a question</a> right next to that section.</p>
<p>The examples above all use MIME type <code>text/html</code>, as this is what the example DOIs resolve to by default. I don’t if and how publishers have implemented fragment identifiers for other formats such as PDF or ePub, and what happens if you combine fragment identifiers with <a href="http://www.crosscite.org/cn/">content negotiation</a>. The shortDOI service works with fragment identifiers as well: <a href="http://doi.org/pxd#decision-letter">http://doi.org/pxd#decision-letter</a>. Another interesting question would be how fragment identifiers are handled for datasets. Typically separate DOIs are assigned for multiple related datasets, but there could also be a place for fragment identifiers as well, e.g. to specify a subset via a date range. The solution depends again on the content type, and the popular <code>text/csv</code> is unfortunately not well suited for this, whereas JSON – using <a href="http://tools.ietf.org/html/rfc6901">JSON Pointer</a> – would work well.</p>
<p><em>Update 8/2/14: <a href="https://twitter.com/ldodds">Leigh Dodds</a> points out that handling the fragment identifier is up to the client and the fragment identifier is not sent to the server. Acrobat reader for example supports the <code>#page=</code> fragment identifier. He also mentions that there is a <a href="http://tools.ietf.org/html/rfc7111">RFC7111</a> for fragment identifiers for the text/csv media type - browsers in the future might support something like <code>http://example.com/data.csv#row=5-7</code>.</em></p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One Ring to Rule them All]]></title>
        <id>57359c3c-929d-492b-957f-03e3ca0ef30b</id>
        <link href="https://sensiblescience.io/mfenner/one-ring-to-rule-them-all"/>
        <updated>2014-07-30T15:29:00.000Z</updated>
        <summary type="html"><![CDATA[One Ring to rule them all, One Ring to find them, One Ring to bring them all and in the darkness bind them.Yesterday 60 years ago the first volume of the <em>Lord of the Rings</em> trilogy by <em>J.R.R. Tolkien</em> was published....]]></summary>
        <content type="html"><![CDATA[<blockquote>
One Ring to rule them all, One Ring to find them, One Ring to bring them all and in the darkness bind them.
</blockquote>
<p>Yesterday 60 years ago the first volume of the <em>Lord of the Rings</em> trilogy by <em>J.R.R. Tolkien</em> was published. The quote above obviously doesn’t quiet apply to scholarly publishing, but one recurring theme that I have often heard in the last few years is that of a need for a canonical digital document format for scholarly content that rules all other formats.</p>
<figure>
<img src="http://blog.martinfenner.org/images/rings.png" class="kg-image" alt="Document formats in scholarly Publishing" /><figcaption aria-hidden="true">Document formats in scholarly Publishing</figcaption>
</figure>
<p>A few years ago almost everyone you would have said that <code>xml</code> is that format, with the NLM Archiving and Interchange Tag Suite - which has evolved into <a href="http://jats.nlm.nih.gov/publishing/">JATS</a> - probably the most commonly used Document Type Definition (DTD). <code>xml</code> does many things really well, but also has important shortcomings, most importantly that it is probably not a good format for authors (and don’t tell me that <code>docx</code> and <code>odt</code> are XML-based). We therefore don’t really expect authors to submit manuscripts in JATS <code>xml</code>, but rather convert documents into this format after a manuscript has been accepted for publication. This conversion step is often time-consuming and labor-intensive.</p>
<p>More recently <code>html</code> has become the most interesting candidate for a canonical scholarly document format. The big advantage over <code>xml</code> is that <code>html</code> - or at least <code>html5</code> which is most popular today - is an attractive format for online authoring tools (that is why <code>html</code> is listed both as input and output format) The downside of this flexibility is that it is much harder to embed structure and metadata into <code>html5</code> compared to <code>xml</code>. There are initiatives such as <a href="http://schema.org/">schema.org</a> and <a href="https://github.com/oreillymedia/HTMLBook">HTMLBook</a> that hope to change that, but we aren’t quite there yet.</p>
<p>Or maybe we should learn from Tolkien and give up on the idea of a canonical document format and rather spend our energy on building tools that make it easier to transition from one format to another. <a href="https://pandoc.org">Pandoc</a> is such as tool, but can’t do all the required conversions, e.g. it can’t yet use <code>docx</code> as input. The downside here is that every file conversion runs the risk of loosing important information. But the increase in flexibility hopefully outweights these shortcomings.</p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Don't Reinvent the Wheel]]></title>
        <id>f93ac598-d96f-40ec-85ec-e917098eccfe</id>
        <link href="https://sensiblescience.io/mfenner/dont-reinvent-the-wheel"/>
        <updated>2014-07-24T15:33:00.000Z</updated>
        <summary type="html"><![CDATA[In a post last week I talked about roads and stagecoaches, and how work on scholarly infrastructure can often be more important than building customer-facing apps. One important aspect of that infrastructure work is to not duplicate efforts.Image by...]]></summary>
        <content type="html"><![CDATA[<p>In a <a href="https://sensiblescience.io/mfenner/build-roads-not-stagecoaches/">post last week</a> I talked about roads and stagecoaches, and how work on scholarly infrastructure can often be more important than building customer-facing apps. One important aspect of that infrastructure work is to not duplicate efforts.</p>
<figure>
<img src="https://assets.sensiblescience.io/ghost/2021/March/14th/5673321593_e6a7faa36d_z.jpg" class="kg-image" alt="Image by Cocoabiscuit on Flickr" /><figcaption aria-hidden="true">Image by Cocoabiscuit <a href="https://www.flickr.com/photos/jfgallery/5673321593/">on Flickr</a></figcaption>
</figure>
<p>A good example is information (or metadata) about scholarly publications. I am the technical lead for the open source <a href="http://articlemetrics.github.io/">article-level metrics (ALM) software</a>. This software can be used in different ways, but most people use it for tracking the metrics of scholarly articles, with articles that have DOIs issued by CrossRef. The ALM software needs three pieces of information for every article: <strong><strong>DOI</strong></strong>, <strong><strong>publication date</strong></strong>, and <strong><strong>title</strong></strong>. This information can be entered via a web interface, but that is of course not very practical for adding dozens or hundreds of articles at a time. The ALM software has therefore long supported the import of multiple articles via a text file and the command line.</p>
<p>This approach is working fine for the ALM software <a href="http://articlemetrics.github.io/plos/">running at PLOS since 2009</a>, but is for example a problem if the ALM software runs as a service for multiple publishers. A more flexible approach is to provide an API to upload articles, and I’ve <a href="http://articlemetrics.github.io/docs/api/">added an API</a> for creating, updating and deleting articles in January 2014.</p>
<p>While the API is an improvement, it still requires the integration into a number of possibly very different publisher workflows, and you have to deal with setting up the permissions, e.g. so that publisher A can’t delete an article from publisher B.</p>
<p>The next ALM release (3.3) will therefore add a third approach to importing articles: using the <a href="http://api.crossref.org/">CrossRef API</a> to look up article information. Article-level metrics is about tracking already published works, so we really only care about articles that have DOIs registered with CrossRef and are therefore published. ALM is now talking to a single API, and this makes it much easier to do this for a number of publishers without writing custom code. Since ALM is an open source application already used by several publishers that aspect is important. And because we are importing, we have don’t have to worry about permissions. The only requirement is that CrossRef has the correct article information, and has this information as soon as possible after publication.</p>
<p>At this point I have a confession to make: I regularly use other CrossRef APIs, but wasn’t aware of <strong><strong>api.crossref.org</strong></strong> until fairly recently. That is sort of understandable since the reference platform was deployed only September last year. The documentation to get you started is on <a href="https://github.com/CrossRef/rest-api-doc/blob/master/rest_api.md">Github</a> and the version history shows frequent API updates (now at v22). The API will return all kinds of information, e.g.</p>
<ul>
<li>how many articles has publisher x published in 2012</li>
<li>percentage of DOIs of publisher Y that include at least one ORCID identifier</li>
<li>list all books with a Creative Commons CC-BY license that were published this year</li>
</ul>
<p>Funder (via FundRef) information is also included, but is still incomplete. Another interesting result is the number of <a href="https://sensiblescience.io/mfenner/direct-links-to-figures-and-tables-using-component-dois/">component DOIs</a> (DOIs for figures, tables or other parts of a document) per year:</p>
<p>For my specific use case I wanted an API call that returns all articles published by PLOS (or any other publisher) in the last day which I can then run regularly. To get all DOIs from a specific publisher, use their CrossRef member ID - DOI prefixes don’t work, as publishers can own more than one DOI prefix. To make this task a little easier I built a CrossRef member search interface into the ALM application:</p>
<figure>
<img src="https://editor.sensiblescience.io/content/images/2021/02/crossref_api.png" class="kg-image" />
</figure>
<p>We can filter API responses by publication date, but it is a better idea to use the update date, as it is possible that the metadata have changed, e.g. a correction of the title. We also want to increase the number of results per page (using the <code>rows</code> parameter). The final API call for all DOIs updated by PLOS since the beginning of the week would be</p>
<pre><code>http://api.crossref.org/members/340/works?filter=from-update-date:2014-07-21,until-update-date:2014-07-24&amp;rows=1000</code></pre>
<p>The next step is of course to parse the JSON of the API response, and you will notice that CrossRef is using <a href="http://gsl-nagoya-u.net/http/pub/citeproc-doc.html">Citeproc JSON</a>. This is a standard JSON format for bibliographic information used internally by several reference managers for citation styles, but increasingly also by APIs and other places where you encounter bibliographic information.</p>
<p>Citeproc JSON is helpful for one particular problem with CrossRef metadata: the exact publication date for an article is not always known, and CrossRef (and similarly DataCite) only requires the publication year. Citeproc JSON can nicely handle partial dates, e.g. year-month:</p>
<pre><code>issued: {
  date-parts: [
    [
      2014,
      7
    ]
  ]
},</code></pre>
<p>I think that a similar approach will work for many other systems that require bibliographic information about scholarly content with CrossRef DOIs. If are not already using <strong><strong>api.crossref.org</strong></strong>, consider integrating with it, I find the API fast, well documented, easy to use - and CrossRef is very responsive to feedback. As you can always wish for more, I would like to see the following: fix the problem were some journal articles are missing the publication date (a required field, even if only the year), and consider adding the canonical URL to the article metadata (which ALM currently has to look up itself, and which is needed to track social media coverage of an article).</p>
<p><em>Update July 24, 2014: added chart with number of component DOIs per year</em></p>
]]></content>
        <author>
            <name>Martin Fenner</name>
            <uri>https://orcid.org/0000-0003-1419-2405</uri>
        </author>
    </entry>
</feed>